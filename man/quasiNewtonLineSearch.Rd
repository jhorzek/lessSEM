% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/quasiNewtonBFGS.R
\name{quasiNewtonLineSearch}
\alias{quasiNewtonLineSearch}
\title{quasiNewtonLineSearch}
\usage{
quasiNewtonLineSearch(
  SEM,
  N,
  individualPenaltyFunction,
  currentTuningParameters,
  penaltyFunctionArguments,
  oldParameters,
  oldM2LL,
  oldGradients,
  oldHessian,
  direction,
  stepSize,
  sig,
  gam,
  maxIterLine
)
}
\arguments{
\item{SEM}{model of class Rcpp_SEMCpp.}

\item{N}{sample size}

\item{oldParameters}{parameters of previous iteration}

\item{oldM2LL}{-2 log likelihood of previous iteration}

\item{oldGradients}{gradients of previous iteration}

\item{oldHessian}{Hessian approximation of previous iteration}

\item{direction}{vector with step direction}

\item{stepSize}{Initial stepsize of the outer iteration (theta_{k+1} = theta_k + Stepsize \* Stepdirection)}

\item{sig}{only relevant when lineSearch = 'GLMNET'. Controls the sigma parameter in Yuan, G.-X., Ho, C.-H., & Lin, C.-J. (2012). An improved GLMNET for l1-regularized logistic regression. The Journal of Machine Learning Research, 13, 1999–2030. https://doi.org/10.1145/2020408.2020421.}

\item{gam}{Controls the gamma parameter in Yuan, G.-X., Ho, C.-H., & Lin, C.-J. (2012). An improved GLMNET for l1-regularized logistic regression. The Journal of Machine Learning Research, 13, 1999–2030. https://doi.org/10.1145/2020408.2020421. Defaults to 0.}

\item{maxIterLine}{maximal number of iterations for line search}

\item{regularizedParameterLabels}{labels of regularized parameters}

\item{adaptiveLassoWeights}{vector with weights for adaptive LASSO. Set to NULL if not using adaptive LASSO}

\item{lambda}{lasso tuning parameter. Higher values = higher penalty}
}
\description{
performs a line search procedure adapted from Yuan, G.-X., Ho, C.-H., & Lin, C.-J. (2012). An improved GLMNET for l1-regularized logistic regression. The Journal of Machine Learning Research, 13, 1999–2030. https://doi.org/10.1145/2020408.2020421 Equation 20.
}
