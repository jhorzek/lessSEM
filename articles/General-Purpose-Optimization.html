<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="lessSEM">
<title>General-Purpose-Optimization • lessSEM</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="General-Purpose-Optimization">
<meta property="og:description" content="lessSEM">
<meta property="og:image" content="/logo.svg">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">lessSEM</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.4.7</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../articles/lessSEM.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/Definition-Variables-and-Multi-Group-SEM.html">Definition-Variables-and-Multi-Group-SEM</a>
    <a class="dropdown-item" href="../articles/General-Purpose-Optimization.html">General-Purpose-Optimization</a>
    <a class="dropdown-item" href="../articles/Mixed-Penalties.html">Mixed Penalties</a>
    <a class="dropdown-item" href="../articles/Parameter-transformations.html">Parameter-transformations</a>
    <a class="dropdown-item" href="../articles/SCAD-and-MCP.html">SCAD-and-MCP</a>
    <a class="dropdown-item" href="../articles/The-Structural-Equation-Model.html">The-Structural-Equation-Model</a>
    <a class="dropdown-item" href="../articles/The-optimizer-interface.html">The-optimizer-interface</a>
    <a class="dropdown-item" href="../articles/log-likelihood-gradients.html">log-likelihood-gradients</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/jhorzek/lessSEM/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.svg" class="logo" alt=""><h1>General-Purpose-Optimization</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/jhorzek/lessSEM/blob/HEAD/vignettes/General-Purpose-Optimization.Rmd" class="external-link"><code>vignettes/General-Purpose-Optimization.Rmd</code></a></small>
      <div class="d-none name"><code>General-Purpose-Optimization.Rmd</code></div>
    </div>

    
    
<p><strong>lessSEM</strong> can be used for regularized SEM and for
general purpose optimization. That is, you can use all optimizers and
penalty functions implemented in <strong>lessSEM</strong> for your own
models. To this end, you must define a fitting function; i.e., a
function which takes in the parameters and returns a single value - the
unregularized fit. <strong>lessSEM</strong> then uses this fitting
function and adds the penalty terms. The combined fitting function is
then optimized. Currently, there are three ways to use the optimizers in
<strong>lessSEM</strong></p>
<ol style="list-style-type: decimal">
<li>You can use the R interface. This interface is very similar to that
of optim (see e.g., <code><a href="../reference/gpLasso.html">?lessSEM::gpLasso</a></code>).</li>
<li>If your functions are defined in C++, you can use a faster interface
which is a bit more involved (see e.g.,
<code><a href="../reference/gpLassoCpp.html">?lessSEM::gpLassoCpp</a></code>).</li>
<li>You can include the header files of <strong>lessSEM</strong> in your
package to directly interface to the underlying C++ functions. This is
the most complicated approach.</li>
</ol>
<p>In general, the approaches get faster as you transition from 1 to 3.
You will see the largest performance gains when implementing a gradient
function and not just a fitting function, however. As a rule of thumb:
Use approach 1 if you intend to run your model a few times, don’t want
to create a new package and your model runs fairly fast. Use approach 2
if you want to increase the speed a bit, while keeping the changes
necessary to your files manageable. Use approach 3 if you create a new
package, have some experience with <strong>RcppArmadillo</strong> and
want to get the best performance.</p>
<p>In the following, we will demonstrate all three approaches using a
linear regression model as an example.</p>
<div class="section level2">
<h2 id="the-example">The example<a class="anchor" aria-label="anchor" href="#the-example"></a>
</h2>
<p>Let’s start by setting up our linear regression model. To this end,
we will simulate a data set:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># first, we simulate data for our</span></span>
<span><span class="co"># linear regression.</span></span>
<span><span class="va">N</span> <span class="op">&lt;-</span> <span class="fl">100</span> <span class="co"># number of persons</span></span>
<span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">10</span> <span class="co"># number of predictors</span></span>
<span><span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">N</span><span class="op">*</span><span class="va">p</span><span class="op">)</span>, nrow <span class="op">=</span> <span class="va">N</span>, ncol <span class="op">=</span> <span class="va">p</span><span class="op">)</span> <span class="co"># design matrix</span></span>
<span><span class="va">b</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">4</span><span class="op">)</span>,</span>
<span>       <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">6</span><span class="op">)</span><span class="op">)</span> <span class="co"># true regression weights</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">X</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="va">b</span>,ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="va">N</span>,<span class="fl">0</span>,<span class="fl">.2</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="the-first-approach-interfacing-from-r">The first approach: Interfacing from R<a class="anchor" aria-label="anchor" href="#the-first-approach-interfacing-from-r"></a>
</h2>
<p>We will now try to implement a lasso regularized linear regression
using the gpLasso interface. This interface is very similar to
<code>optim</code>. To use it, we must define our fitting function in
R:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># defining the sum-squared-errors:</span></span>
<span><span class="va">sseFun</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">par</span>, <span class="va">y</span>, <span class="va">X</span>, <span class="va">N</span><span class="op">)</span><span class="op">{</span></span>
<span>  <span class="co"># par is the parameter vector</span></span>
<span>  <span class="co"># y is the observed dependent variable</span></span>
<span>  <span class="co"># X is the design matrix</span></span>
<span>  <span class="co"># N is the sample size</span></span>
<span>  <span class="va">pred</span> <span class="op">&lt;-</span> <span class="va">X</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="va">par</span>, ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="co">#be explicit here:</span></span>
<span>  <span class="co"># we need par to be a column vector</span></span>
<span>  <span class="va">sse</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="op">(</span><span class="va">y</span> <span class="op">-</span> <span class="va">pred</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span>  <span class="co"># we scale with .5/N to get the same results as glmnet</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="op">(</span><span class="fl">.5</span><span class="op">/</span><span class="va">N</span><span class="op">)</span><span class="op">*</span><span class="va">sse</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>Additionally, we need a <em>labeled</em> vector with starting
values:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">par</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">p</span><span class="op">+</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/names.html" class="external-link">names</a></span><span class="op">(</span><span class="va">par</span><span class="op">)</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"b"</span>, <span class="fl">0</span><span class="op">:</span><span class="va">p</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">par</span><span class="op">)</span></span>
<span><span class="co">#&gt;  b0  b1  b2  b3  b4  b5  b6  b7  b8  b9 b10 </span></span>
<span><span class="co">#&gt;   0   0   0   0   0   0   0   0   0   0   0</span></span></code></pre></div>
<p>Note that we defined one more parameter than there are variables in
X. This is because we also want to estimate the intercept. To this end,
we extend X:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">Xext</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html" class="external-link">cbind</a></span><span class="op">(</span><span class="fl">1</span>,<span class="va">X</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">Xext</span><span class="op">)</span></span>
<span><span class="co">#&gt;      [,1]        [,2]        [,3]       [,4]       [,5]        [,6]        [,7]</span></span>
<span><span class="co">#&gt; [1,]    1 -0.56047565 -0.71040656  2.1988103 -0.7152422 -0.07355602 -0.60189285</span></span>
<span><span class="co">#&gt; [2,]    1 -0.23017749  0.25688371  1.3124130 -0.7526890 -1.16865142 -0.99369859</span></span>
<span><span class="co">#&gt; [3,]    1  1.55870831 -0.24669188 -0.2651451 -0.9385387 -0.63474826  1.02678506</span></span>
<span><span class="co">#&gt; [4,]    1  0.07050839 -0.34754260  0.5431941 -1.0525133 -0.02884155  0.75106130</span></span>
<span><span class="co">#&gt; [5,]    1  0.12928774 -0.95161857 -0.4143399 -0.4371595  0.67069597 -1.50916654</span></span>
<span><span class="co">#&gt; [6,]    1  1.71506499 -0.04502772 -0.4762469  0.3311792 -1.65054654 -0.09514745</span></span>
<span><span class="co">#&gt;             [,8]       [,9]      [,10]      [,11]</span></span>
<span><span class="co">#&gt; [1,]  1.07401226 -0.7282191  0.3562833 -1.0141142</span></span>
<span><span class="co">#&gt; [2,] -0.02734697 -1.5404424 -0.6580102 -0.7913139</span></span>
<span><span class="co">#&gt; [3,] -0.03333034 -0.6930946  0.8552022  0.2995937</span></span>
<span><span class="co">#&gt; [4,] -1.51606762  0.1188494  1.1529362  1.6390519</span></span>
<span><span class="co">#&gt; [5,]  0.79038534 -1.3647095  0.2762746  1.0846170</span></span>
<span><span class="co">#&gt; [6,] -0.21073418  0.5899827  0.1441047 -0.6245675</span></span></code></pre></div>
<p>Finally, we need to decide which parameters should be regularized and
the values for lambda. We want to regularize everything except for the
intercept:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="va">regularized</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"b"</span>, <span class="fl">1</span><span class="op">:</span><span class="va">p</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;  [1] "b1"  "b2"  "b3"  "b4"  "b5"  "b6"  "b7"  "b8"  "b9"  "b10"</span></span>
<span><span class="va">lambdas</span>  <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">.1</span>,length.out <span class="op">=</span> <span class="fl">20</span><span class="op">)</span></span></code></pre></div>
<p>Now, we are ready to estimate the model:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/jhorzek/lessSEM" class="external-link">lessSEM</a></span><span class="op">)</span></span>
<span><span class="va">l1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/gpLasso.html">gpLasso</a></span><span class="op">(</span>par <span class="op">=</span> <span class="va">par</span>, </span>
<span>              regularized <span class="op">=</span> <span class="va">regularized</span>, </span>
<span>              fn <span class="op">=</span> <span class="va">sseFun</span>, </span>
<span>              lambdas <span class="op">=</span> <span class="va">lambdas</span>, </span>
<span>              X <span class="op">=</span> <span class="va">Xext</span>,</span>
<span>              y <span class="op">=</span> <span class="va">y</span>,</span>
<span>              N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">l1</span><span class="op">@</span><span class="va">parameters</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt;        lambda alpha         b0        b1        b2        b3       b4</span></span>
<span><span class="co">#&gt; 1 0.000000000     1 0.02738472 1.0129194 0.9991454 0.9705725 1.027626</span></span>
<span><span class="co">#&gt; 2 0.005263158     1 0.02935305 1.0043738 0.9908933 0.9626258 1.025138</span></span>
<span><span class="co">#&gt; 3 0.010526316     1 0.02995106 0.9967095 0.9846669 0.9552793 1.021892</span></span>
<span><span class="co">#&gt; 4 0.015789474     1 0.03010651 0.9897340 0.9789419 0.9481495 1.018673</span></span>
<span><span class="co">#&gt; 5 0.021052632     1 0.03029749 0.9827290 0.9732058 0.9409863 1.015363</span></span>
<span><span class="co">#&gt; 6 0.026315789     1 0.03112509 0.9753348 0.9670620 0.9338614 1.011553</span></span>
<span><span class="co">#&gt;           b5           b6          b7          b8           b9         b10</span></span>
<span><span class="co">#&gt; 1 0.01403601 -0.007460964 0.018589924 0.021930771 -0.009900077 0.027401044</span></span>
<span><span class="co">#&gt; 2 0.00336578  0.000000000 0.014341067 0.015434757 -0.007939455 0.022297544</span></span>
<span><span class="co">#&gt; 3 0.00000000  0.000000000 0.009622163 0.010707922 -0.005256532 0.017465353</span></span>
<span><span class="co">#&gt; 4 0.00000000  0.000000000 0.004932662 0.006363847 -0.002393164 0.012712886</span></span>
<span><span class="co">#&gt; 5 0.00000000  0.000000000 0.000177806 0.002036023  0.000000000 0.007969732</span></span>
<span><span class="co">#&gt; 6 0.00000000  0.000000000 0.000000000 0.000000000  0.000000000 0.003303750</span></span></code></pre>
<p>Note that we did not specify the gradients of our function. In this
case, <strong>lessSEM</strong> will use <strong>numDeriv</strong> to
compute the gradients. However, if you know how to specify the
gradients, this can result in faster estimation:</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">sseGrad</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">par</span>, <span class="va">y</span>, <span class="va">X</span>, <span class="va">N</span><span class="op">)</span><span class="op">{</span></span>
<span>  </span>
<span>  <span class="va">gradients</span> <span class="op">=</span> <span class="op">(</span><span class="op">-</span><span class="fl">2.0</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span> <span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span> <span class="va">y</span> <span class="op">+</span> <span class="fl">2.0</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">X</span><span class="op">)</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span><span class="va">X</span><span class="op"><a href="https://rdrr.io/r/base/matmult.html" class="external-link">%*%</a></span><span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="va">par</span>,ncol <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span>  </span>
<span>  <span class="va">gradients</span> <span class="op">=</span> <span class="op">(</span><span class="fl">.5</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span><span class="op">*</span><span class="va">gradients</span></span>
<span>  <span class="kw"><a href="https://rdrr.io/r/base/function.html" class="external-link">return</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/t.html" class="external-link">t</a></span><span class="op">(</span><span class="va">gradients</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">}</span></span></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">l1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/gpLasso.html">gpLasso</a></span><span class="op">(</span>par <span class="op">=</span> <span class="va">par</span>, </span>
<span>              regularized <span class="op">=</span> <span class="va">regularized</span>, </span>
<span>              fn <span class="op">=</span> <span class="va">sseFun</span>, </span>
<span>              gr <span class="op">=</span> <span class="va">sseGrad</span>,</span>
<span>              lambdas <span class="op">=</span> <span class="va">lambdas</span>, </span>
<span>              X <span class="op">=</span> <span class="va">Xext</span>,</span>
<span>              y <span class="op">=</span> <span class="va">y</span>,</span>
<span>              N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">l1</span><span class="op">@</span><span class="va">parameters</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt;        lambda alpha         b0        b1        b2        b3       b4</span></span>
<span><span class="co">#&gt; 1 0.000000000     1 0.02738485 1.0129200 0.9991452 0.9705725 1.027626</span></span>
<span><span class="co">#&gt; 2 0.005263158     1 0.02935325 1.0043732 0.9908928 0.9626258 1.025139</span></span>
<span><span class="co">#&gt; 3 0.010526316     1 0.02995023 0.9967094 0.9846669 0.9552792 1.021892</span></span>
<span><span class="co">#&gt; 4 0.015789474     1 0.03010649 0.9897330 0.9789426 0.9481493 1.018672</span></span>
<span><span class="co">#&gt; 5 0.021052632     1 0.03029729 0.9827286 0.9732062 0.9409869 1.015362</span></span>
<span><span class="co">#&gt; 6 0.026315789     1 0.03112481 0.9753368 0.9670620 0.9338616 1.011553</span></span>
<span><span class="co">#&gt;            b5           b6           b7          b8           b9         b10</span></span>
<span><span class="co">#&gt; 1 0.014034994 -0.007460252 0.0185901898 0.021930702 -0.009900699 0.027400748</span></span>
<span><span class="co">#&gt; 2 0.003364951  0.000000000 0.0143418480 0.015434447 -0.007939640 0.022297136</span></span>
<span><span class="co">#&gt; 3 0.000000000  0.000000000 0.0096217573 0.010707383 -0.005257048 0.017465134</span></span>
<span><span class="co">#&gt; 4 0.000000000  0.000000000 0.0049332838 0.006363868 -0.002393522 0.012713116</span></span>
<span><span class="co">#&gt; 5 0.000000000  0.000000000 0.0001772169 0.002036300  0.000000000 0.007969996</span></span>
<span><span class="co">#&gt; 6 0.000000000  0.000000000 0.0000000000 0.000000000  0.000000000 0.003303777</span></span></code></pre>
<p>Here is a short comparison of running both models 5 times each:</p>
<p>Runtime in seconds without gradients:</p>
<pre><code><span><span class="co">#&gt; [1] 0.4024107 0.4116023 0.3960397 0.4052355 0.3961325</span></span></code></pre>
<p>Runtime in seconds with gradients:</p>
<pre><code><span><span class="co">#&gt; [1] 0.03961349 0.04693389 0.04001808 0.04008436 0.04523945</span></span></code></pre>
<p>Now, that’s quite a difference!</p>
<p>Note that you can also pass a C++ function to gpLasso similar to the
approach above:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/RcppCore/RcppArmadillo" class="external-link">RcppArmadillo</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://www.rcpp.org" class="external-link">Rcpp</a></span><span class="op">)</span></span>
<span><span class="va">linreg</span> <span class="op">&lt;-</span> <span class="st">'</span></span>
<span><span class="st">// [[Rcpp::depends(RcppArmadillo)]]</span></span>
<span><span class="st">#include &lt;RcppArmadillo.h&gt;</span></span>
<span><span class="st"></span></span>
<span><span class="st">// [[Rcpp::export]]</span></span>
<span><span class="st">double fitfunction(const arma::colvec parameters, const arma::mat X, const arma::colvec y, const int N){</span></span>
<span><span class="st">  </span></span>
<span><span class="st">  // compute the sum of squared errors:</span></span>
<span><span class="st">    arma::mat sse = arma::trans(y-X*parameters)*(y-X*parameters);</span></span>
<span><span class="st">    </span></span>
<span><span class="st">    // other packages, such as glmnet, scale the sse with </span></span>
<span><span class="st">    // 1/(2*N), where N is the sample size. We will do that here as well</span></span>
<span><span class="st">    </span></span>
<span><span class="st">    sse *= 1.0/(2.0 * N);</span></span>
<span><span class="st">    </span></span>
<span><span class="st">    // note: We must return a double, but the sse is a matrix</span></span>
<span><span class="st">    // To get a double, just return the single value that is in </span></span>
<span><span class="st">    // this matrix:</span></span>
<span><span class="st">      return(sse(0,0));</span></span>
<span><span class="st">}</span></span>
<span><span class="st"></span></span>
<span><span class="st">// [[Rcpp::export]]</span></span>
<span><span class="st">arma::rowvec gradientfunction(const arma::colvec parameters, const arma::mat X, const arma::colvec y, const int N){</span></span>
<span><span class="st">  </span></span>
<span><span class="st">  // note: we want to return our gradients as row-vector; therefore,</span></span>
<span><span class="st">  // we have to transpose the resulting column-vector:</span></span>
<span><span class="st">    arma::rowvec gradients = arma::trans(-2.0*X.t() * y + 2.0*X.t()*X*parameters);</span></span>
<span><span class="st">    </span></span>
<span><span class="st">    // other packages, such as glmnet, scale the sse with </span></span>
<span><span class="st">    // 1/(2*N), where N is the sample size. We will do that here as well</span></span>
<span><span class="st">    </span></span>
<span><span class="st">    gradients *= (.5/N);</span></span>
<span><span class="st">    </span></span>
<span><span class="st">    return(gradients);</span></span>
<span><span class="st">}'</span></span>
<span></span>
<span><span class="fu">Rcpp</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/Rcpp/man/sourceCpp.html" class="external-link">sourceCpp</a></span><span class="op">(</span>code <span class="op">=</span> <span class="va">linreg</span><span class="op">)</span></span></code></pre></div>
<p>Run the model as before:</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">l1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/gpLasso.html">gpLasso</a></span><span class="op">(</span>par <span class="op">=</span> <span class="va">par</span>, </span>
<span>              regularized <span class="op">=</span> <span class="va">regularized</span>, </span>
<span>              fn <span class="op">=</span> <span class="va">fitfunction</span>, </span>
<span>              gr <span class="op">=</span> <span class="va">gradientfunction</span>,</span>
<span>              lambdas <span class="op">=</span> <span class="va">lambdas</span>, </span>
<span>              X <span class="op">=</span> <span class="va">Xext</span>,</span>
<span>              y <span class="op">=</span> <span class="va">y</span>,</span>
<span>              N <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">l1</span><span class="op">@</span><span class="va">parameters</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt;        lambda alpha         b0        b1        b2        b3       b4</span></span>
<span><span class="co">#&gt; 1 0.000000000     1 0.02738540 1.0129199 0.9991451 0.9705723 1.027625</span></span>
<span><span class="co">#&gt; 2 0.005263158     1 0.02935207 1.0043733 0.9908930 0.9626262 1.025139</span></span>
<span><span class="co">#&gt; 3 0.010526316     1 0.02994985 0.9967091 0.9846669 0.9552794 1.021892</span></span>
<span><span class="co">#&gt; 4 0.015789474     1 0.03010681 0.9897326 0.9789426 0.9481493 1.018672</span></span>
<span><span class="co">#&gt; 5 0.021052632     1 0.03029735 0.9827286 0.9732060 0.9409868 1.015363</span></span>
<span><span class="co">#&gt; 6 0.026315789     1 0.03112467 0.9753370 0.9670622 0.9338616 1.011553</span></span>
<span><span class="co">#&gt;            b5           b6           b7          b8           b9         b10</span></span>
<span><span class="co">#&gt; 1 0.014036116 -0.007460446 0.0185897976 0.021930567 -0.009900272 0.027401106</span></span>
<span><span class="co">#&gt; 2 0.003365951  0.000000000 0.0143415907 0.015435060 -0.007939728 0.022297282</span></span>
<span><span class="co">#&gt; 3 0.000000000  0.000000000 0.0096214449 0.010707751 -0.005256894 0.017464995</span></span>
<span><span class="co">#&gt; 4 0.000000000  0.000000000 0.0049330966 0.006364175 -0.002393745 0.012713250</span></span>
<span><span class="co">#&gt; 5 0.000000000  0.000000000 0.0001769795 0.002036461  0.000000000 0.007970247</span></span>
<span><span class="co">#&gt; 6 0.000000000  0.000000000 0.0000000000 0.000000000  0.000000000 0.003304510</span></span></code></pre>
<p>The runtime in seconds with C++ is:</p>
<pre><code><span><span class="co">#&gt; [1] 0.03466702 0.03700900 0.02999139 0.03110766 0.03342867</span></span></code></pre>
<p>Which is even lower than what we had before!</p>
</div>
<div class="section level2">
<h2 id="the-second-approach-using-c-function-pointers">The second approach: Using C++ function pointers<a class="anchor" aria-label="anchor" href="#the-second-approach-using-c-function-pointers"></a>
</h2>
<p>While using the Rcpp functions defined above was quite fast for our
linear regression, it can still be fairly slow for more involved models
(e.g., SEM). This is due to our optimizer having to go back and forth
between R and C++. To reduce this overhead, we can use the second
approach. Here, instead of passing an Rcpp function which is then
executed in R, we pass a pointer to the underlying C++ functions. This
approach is more constrained than the one presented above:</p>
<ol style="list-style-type: decimal">
<li>We must define both, a fitting function and a gradient function in
Rcpp. We cannot rely on numDeriv any more!</li>
<li>The fitting function and the gradient function are only allowed two
parameters each: a <code>const Rcpp::NumericVector&amp;</code> (the
parameters) and an <code>Rcpp::List&amp;</code> (everything else). While
this seems restrictive, note that we can virtually pass anything we want
in a list.</li>
<li>We must <a href="https://gallery.rcpp.org/articles/passing-cpp-function-pointers/" class="external-link">create
pointers</a> to the fit and gradient function. This is difficult,
however we will provide some guidance below.</li>
</ol>
<p>This may be a bit overwhelming at first, so we will go through it
step by step.</p>
<div class="section level3">
<h3 id="creating-a-fitting-function-and-a-gradient-function">1. Creating a fitting function and a gradient function<a class="anchor" aria-label="anchor" href="#creating-a-fitting-function-and-a-gradient-function"></a>
</h3>
<p>We already defined a fitting function and a gradient function for our
linear regression model in the example above. However, we often do not
know the gradients in closed form. If you don’t have a gradient
function, you can try a numerical approximation. More details can be
found <a href="https://en.wikipedia.org/wiki/Finite_difference" class="external-link">here</a>.</p>
</div>
<div class="section level3">
<h3 id="adapting-the-functions-to-the-constraints">2. Adapting the functions to the constraints<a class="anchor" aria-label="anchor" href="#adapting-the-functions-to-the-constraints"></a>
</h3>
<p>Note that our fitting function and our gradient function do not
comply with the constraints mentioned above. That is, they do take more
than two parameters as arguments
(<code>const arma::colvec parameters, const arma::mat X, const arma::colvec y, const int N</code>),
and these arguments are not a
<code>const Rcpp::NumericVector&amp;</code> and an
<code>Rcpp::List&amp;</code>. How can we make this work? The parameter
vector <code>const Rcpp::NumericVector&amp;</code> will hold all
elements in the <code>arma::colvec pararameters</code> of our old
function. The <code>Rcpp::List&amp;</code> must contain all of the other
elements (<code>X,y,N</code>). Let’s start by creating this list, which
we will call data:</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span><span class="st">"X"</span> <span class="op">=</span> <span class="va">Xext</span>,</span>
<span>             <span class="st">"y"</span> <span class="op">=</span> <span class="va">y</span>,</span>
<span>             <span class="st">"N"</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Next, we have to change our functions to make things work:</p>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">linreg</span> <span class="op">&lt;-</span> <span class="st">'</span></span>
<span><span class="st">// [[Rcpp::depends(RcppArmadillo)]]</span></span>
<span><span class="st">#include &lt;RcppArmadillo.h&gt;</span></span>
<span><span class="st"></span></span>
<span><span class="st">// [[Rcpp::export]]</span></span>
<span><span class="st">double fitfunction(const Rcpp::NumericVector&amp; parameters, Rcpp::List&amp; data){</span></span>
<span><span class="st">  // our function now only takes the two specified arguments: a</span></span>
<span><span class="st">  // const Rcpp::NumericVector&amp; and an Rcpp::List&amp;.</span></span>
<span><span class="st">  // We have to extract all elements from the list:</span></span>
<span><span class="st">  arma::colvec y = Rcpp::as&lt;arma::colvec&gt;(data["y"]); // the dependent variable</span></span>
<span><span class="st">  arma::mat X = Rcpp::as&lt;arma::mat&gt;(data["X"]); // the design matrix</span></span>
<span><span class="st">  int N = Rcpp::as&lt;int&gt;(data["N"]); // the sample size</span></span>
<span><span class="st">  </span></span>
<span><span class="st">  // Next, we want to get the parameters as a column-vector:</span></span>
<span><span class="st">    arma::colvec b = Rcpp::as&lt;arma::colvec&gt;(parameters);</span></span>
<span><span class="st">    </span></span>
<span><span class="st">  // compute the sum of squared errors:</span></span>
<span><span class="st">    arma::mat sse = arma::trans(y-X*b)*(y-X*b);</span></span>
<span><span class="st">    </span></span>
<span><span class="st">    // other packages, such as glmnet, scale the sse with </span></span>
<span><span class="st">    // 1/(2*N), where N is the sample size. We will do that here as well</span></span>
<span><span class="st">    </span></span>
<span><span class="st">    sse *= 1.0/(2.0 * N);</span></span>
<span><span class="st">    </span></span>
<span><span class="st">    // note: We must return a double, but the sse is a matrix</span></span>
<span><span class="st">    // To get a double, just return the single value that is in </span></span>
<span><span class="st">    // this matrix:</span></span>
<span><span class="st">      return(sse(0,0));</span></span>
<span><span class="st">}</span></span>
<span><span class="st"></span></span>
<span><span class="st">// [[Rcpp::export]]</span></span>
<span><span class="st">arma::rowvec gradientfunction(const Rcpp::NumericVector&amp; parameters, Rcpp::List&amp; data){</span></span>
<span><span class="st">    // our function now only takes the two specified arguments: a</span></span>
<span><span class="st">  // const Rcpp::NumericVector&amp; and an Rcpp::List&amp;.</span></span>
<span><span class="st">  // We have to extract all elements from the list:</span></span>
<span><span class="st">  arma::colvec y = Rcpp::as&lt;arma::colvec&gt;(data["y"]); // the dependent variable</span></span>
<span><span class="st">  arma::mat X = Rcpp::as&lt;arma::mat&gt;(data["X"]); // the design matrix</span></span>
<span><span class="st">  int N = Rcpp::as&lt;int&gt;(data["N"]); // the sample size</span></span>
<span><span class="st">  </span></span>
<span><span class="st">  // Next, we want to get the parameters as a column-vector:</span></span>
<span><span class="st">    arma::colvec b = Rcpp::as&lt;arma::colvec&gt;(parameters);</span></span>
<span><span class="st">  </span></span>
<span><span class="st">  // note: we want to return our gradients as row-vector; therefore,</span></span>
<span><span class="st">  // we have to transpose the resulting column-vector:</span></span>
<span><span class="st">    arma::rowvec gradients = arma::trans(-2.0*X.t() * y + 2.0*X.t()*X*b);</span></span>
<span><span class="st">    </span></span>
<span><span class="st">    // other packages, such as glmnet, scale the sse with </span></span>
<span><span class="st">    // 1/(2*N), where N is the sample size. We will do that here as well</span></span>
<span><span class="st">    </span></span>
<span><span class="st">    gradients *= (.5/N);</span></span>
<span><span class="st">    </span></span>
<span><span class="st">    return(gradients);</span></span>
<span><span class="st">}</span></span>
<span><span class="st">'</span></span></code></pre></div>
<p>That’s it, our functions have been transformed!</p>
</div>
<div class="section level3">
<h3 id="step-3-creating-pointers-to-our-functions">Step 3: Creating pointers to our functions<a class="anchor" aria-label="anchor" href="#step-3-creating-pointers-to-our-functions"></a>
</h3>
<p>This is where it get’s really tricky! We can’t just pass our
functions to C++. However, we can <a href="https://gallery.rcpp.org/articles/passing-cpp-function-pointers/" class="external-link">create
pointers</a>. These have to be generated in C++ and this can be tricky
to get right. To simplify the process, we have created a function which
helps setting things up:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="fu">lessSEM</span><span class="fu">::</span><span class="fu"><a href="../reference/makePtrs.html">makePtrs</a></span><span class="op">(</span>fitFunName <span class="op">=</span> <span class="st">"fitfunction"</span>, <span class="co"># name of the function in C++</span></span>
<span>                      gradFunName <span class="op">=</span> <span class="st">"gradientfunction"</span> <span class="co"># name of the function in C++</span></span>
<span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; // INSTRUCTIONS: ADD THE FOLLOWING LINES TO YOUR C++ FUNCTIONS</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; // IF RCPPARMADILLO IS NOT IMPORTED YET, UNCOMMENT THE FOLLOWING TWO LINES</span></span>
<span><span class="co">#&gt; // // [[Rcpp::depends(RcppArmadillo)]]</span></span>
<span><span class="co">#&gt; // #include &lt;RcppArmadillo.h&gt;</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; // Dirk Eddelbuettel at</span></span>
<span><span class="co">#&gt; // https://gallery.rcpp.org/articles/passing-cpp-function-pointers/</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; typedef double (*fitFunPtr)(const Rcpp::NumericVector&amp;, //parameters</span></span>
<span><span class="co">#&gt;                 Rcpp::List&amp; //additional elements</span></span>
<span><span class="co">#&gt; );</span></span>
<span><span class="co">#&gt; typedef Rcpp::XPtr&lt;fitFunPtr&gt; fitFunPtr_t;</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; typedef arma::rowvec (*gradientFunPtr)(const Rcpp::NumericVector&amp;, //parameters</span></span>
<span><span class="co">#&gt;                       Rcpp::List&amp; //additional elements</span></span>
<span><span class="co">#&gt; );</span></span>
<span><span class="co">#&gt; typedef Rcpp::XPtr&lt;gradientFunPtr&gt; gradientFunPtr_t;</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; // [[Rcpp::export]]</span></span>
<span><span class="co">#&gt; fitFunPtr_t fitfunctionPtr() {</span></span>
<span><span class="co">#&gt;         return(fitFunPtr_t(new fitFunPtr(&amp;fitfunction)));</span></span>
<span><span class="co">#&gt; }</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; // [[Rcpp::export]]</span></span>
<span><span class="co">#&gt; gradientFunPtr_t gradientfunctionPtr() {</span></span>
<span><span class="co">#&gt;         return(gradientFunPtr_t(new gradientFunPtr(&amp;gradientfunction)));</span></span>
<span><span class="co">#&gt; }</span></span></code></pre></div>
<p>Let’s follow the instructions and add the lines to our C++
functions:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">linreg</span> <span class="op">&lt;-</span> <span class="st">'</span></span>
<span><span class="st">// [[Rcpp::depends(RcppArmadillo)]]</span></span>
<span><span class="st">#include &lt;RcppArmadillo.h&gt;</span></span>
<span><span class="st"></span></span>
<span><span class="st">// [[Rcpp::export]]</span></span>
<span><span class="st">double fitfunction(const Rcpp::NumericVector&amp; parameters, Rcpp::List&amp; data){</span></span>
<span><span class="st">  // our function now only takes the two specified arguments: a</span></span>
<span><span class="st">  // const Rcpp::NumericVector&amp; and an Rcpp::List&amp;.</span></span>
<span><span class="st">  // We have to extract all elements from the list:</span></span>
<span><span class="st">  arma::colvec y = Rcpp::as&lt;arma::colvec&gt;(data["y"]); // the dependent variable</span></span>
<span><span class="st">  arma::mat X = Rcpp::as&lt;arma::mat&gt;(data["X"]); // the design matrix</span></span>
<span><span class="st">  int N = Rcpp::as&lt;int&gt;(data["N"]); // the sample size</span></span>
<span><span class="st">  </span></span>
<span><span class="st">  // Next, we want to get the parameters as a column-vector:</span></span>
<span><span class="st">    arma::colvec b = Rcpp::as&lt;arma::colvec&gt;(parameters);</span></span>
<span><span class="st">    </span></span>
<span><span class="st">  // compute the sum of squared errors:</span></span>
<span><span class="st">    arma::mat sse = arma::trans(y-X*b)*(y-X*b);</span></span>
<span><span class="st">    </span></span>
<span><span class="st">    // other packages, such as glmnet, scale the sse with </span></span>
<span><span class="st">    // 1/(2*N), where N is the sample size. We will do that here as well</span></span>
<span><span class="st">    </span></span>
<span><span class="st">    sse *= 1.0/(2.0 * N);</span></span>
<span><span class="st">    </span></span>
<span><span class="st">    // note: We must return a double, but the sse is a matrix</span></span>
<span><span class="st">    // To get a double, just return the single value that is in </span></span>
<span><span class="st">    // this matrix:</span></span>
<span><span class="st">      return(sse(0,0));</span></span>
<span><span class="st">}</span></span>
<span><span class="st"></span></span>
<span><span class="st">// [[Rcpp::export]]</span></span>
<span><span class="st">arma::rowvec gradientfunction(const Rcpp::NumericVector&amp; parameters, Rcpp::List&amp; data){</span></span>
<span><span class="st">    // our function now only takes the two specified arguments: a</span></span>
<span><span class="st">  // const Rcpp::NumericVector&amp; and an Rcpp::List&amp;.</span></span>
<span><span class="st">  // We have to extract all elements from the list:</span></span>
<span><span class="st">  arma::colvec y = Rcpp::as&lt;arma::colvec&gt;(data["y"]); // the dependent variable</span></span>
<span><span class="st">  arma::mat X = Rcpp::as&lt;arma::mat&gt;(data["X"]); // the design matrix</span></span>
<span><span class="st">  int N = Rcpp::as&lt;int&gt;(data["N"]); // the sample size</span></span>
<span><span class="st">  </span></span>
<span><span class="st">  // Next, we want to get the parameters as a column-vector:</span></span>
<span><span class="st">    arma::colvec b = Rcpp::as&lt;arma::colvec&gt;(parameters);</span></span>
<span><span class="st">  </span></span>
<span><span class="st">  // note: we want to return our gradients as row-vector; therefore,</span></span>
<span><span class="st">  // we have to transpose the resulting column-vector:</span></span>
<span><span class="st">    arma::rowvec gradients = arma::trans(-2.0*X.t() * y + 2.0*X.t()*X*b);</span></span>
<span><span class="st">    </span></span>
<span><span class="st">    // other packages, such as glmnet, scale the sse with </span></span>
<span><span class="st">    // 1/(2*N), where N is the sample size. We will do that here as well</span></span>
<span><span class="st">    </span></span>
<span><span class="st">    gradients *= (.5/N);</span></span>
<span><span class="st">    </span></span>
<span><span class="st">    return(gradients);</span></span>
<span><span class="st">}</span></span>
<span><span class="st"></span></span>
<span><span class="st">/// THE FOLLOWING PART IS NEW:</span></span>
<span><span class="st"></span></span>
<span><span class="st">// INSTRUCTIONS: ADD THE FOLLOWING LINES TO YOUR C++ FUNCTIONS</span></span>
<span><span class="st"></span></span>
<span><span class="st">// IF RCPPARMADILLO IS NOT IMPORTED YET, UNCOMMENT THE FOLLOWING TWO LINES</span></span>
<span><span class="st">// // [[Rcpp::depends(RcppArmadillo)]]</span></span>
<span><span class="st">// #include &lt;RcppArmadillo.h&gt;</span></span>
<span><span class="st"></span></span>
<span><span class="st">// Dirk Eddelbuettel at</span></span>
<span><span class="st">// https://gallery.rcpp.org/articles/passing-cpp-function-pointers/</span></span>
<span><span class="st">typedef double (*fitFunPtr)(const Rcpp::NumericVector&amp;, //parameters</span></span>
<span><span class="st">                Rcpp::List&amp; //additional elements</span></span>
<span><span class="st">);</span></span>
<span><span class="st">typedef Rcpp::XPtr&lt;fitFunPtr&gt; fitFunPtr_t;</span></span>
<span><span class="st"></span></span>
<span><span class="st">typedef arma::rowvec (*gradientFunPtr)(const Rcpp::NumericVector&amp;, //parameters</span></span>
<span><span class="st">                      Rcpp::List&amp; //additional elements</span></span>
<span><span class="st">);</span></span>
<span><span class="st">typedef Rcpp::XPtr&lt;gradientFunPtr&gt; gradientFunPtr_t;</span></span>
<span><span class="st"></span></span>
<span><span class="st">// [[Rcpp::export]]</span></span>
<span><span class="st">fitFunPtr_t fitfunctionPtr() {</span></span>
<span><span class="st">        return(fitFunPtr_t(new fitFunPtr(&amp;fitfunction)));</span></span>
<span><span class="st">}</span></span>
<span><span class="st"></span></span>
<span><span class="st">// [[Rcpp::export]]</span></span>
<span><span class="st">gradientFunPtr_t gradientfunctionPtr() {</span></span>
<span><span class="st">        return(gradientFunPtr_t(new gradientFunPtr(&amp;gradientfunction)));</span></span>
<span><span class="st">}</span></span>
<span><span class="st">'</span></span></code></pre></div>
<p>Compile the functions using Rcpp:</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">Rcpp</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/Rcpp/man/sourceCpp.html" class="external-link">sourceCpp</a></span><span class="op">(</span>code <span class="op">=</span> <span class="va">linreg</span><span class="op">)</span></span></code></pre></div>
<p>Great! Now that this is out of the way, we can create the pointers to
our functions:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ffp</span> <span class="op">&lt;-</span> <span class="fu">fitfunctionPtr</span><span class="op">(</span><span class="op">)</span> <span class="co"># create the pointer to the fitting function</span></span>
<span><span class="co"># Note that the name of this function will depend on the name of your fitting function.</span></span>
<span><span class="co"># For instance, if your fitting function is called sse, then the pointer will be created </span></span>
<span><span class="co"># with ffp &lt;- ssePtr()</span></span>
<span><span class="va">gfp</span> <span class="op">&lt;-</span> <span class="fu">gradientfunctionPtr</span><span class="op">(</span><span class="op">)</span> <span class="co"># create the pointer to the gradient function</span></span>
<span><span class="co"># Note that the name of this function will depend on the name of your gradient function.</span></span>
<span><span class="co"># For instance, if your gradient function is called sseGradient, then the pointer will be created </span></span>
<span><span class="co"># with gfp &lt;- sseGradientPtr()</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="optimizing-the-model">Optimizing the model<a class="anchor" aria-label="anchor" href="#optimizing-the-model"></a>
</h3>
<p>The last step is to call the general purpose optimization. To this
end, use the <code>gpLassoCpp</code> function:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">l1</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/gpLassoCpp.html">gpLassoCpp</a></span><span class="op">(</span>par <span class="op">=</span> <span class="va">par</span>, </span>
<span>                 regularized <span class="op">=</span> <span class="va">regularized</span>, </span>
<span>                 <span class="co"># important: pass the poinnters!</span></span>
<span>                 fn <span class="op">=</span> <span class="va">ffp</span>, </span>
<span>                 gr <span class="op">=</span> <span class="va">gfp</span>, </span>
<span>                 lambdas <span class="op">=</span> <span class="va">lambdas</span>, </span>
<span>                 <span class="co"># finally, pass the list which the fitting function and the </span></span>
<span>                 <span class="co"># gradient function need:</span></span>
<span>                 additionalArguments <span class="op">=</span> <span class="va">data</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">l1</span><span class="op">@</span><span class="va">parameters</span><span class="op">)</span></span></code></pre></div>
<pre><code><span><span class="co">#&gt;        lambda alpha         b0        b1        b2        b3       b4</span></span>
<span><span class="co">#&gt; 1 0.000000000     1 0.02738485 1.0129187 0.9991454 0.9705724 1.027625</span></span>
<span><span class="co">#&gt; 2 0.005263158     1 0.02935277 1.0043736 0.9908928 0.9626259 1.025139</span></span>
<span><span class="co">#&gt; 3 0.010526316     1 0.02995028 0.9967094 0.9846668 0.9552792 1.021892</span></span>
<span><span class="co">#&gt; 4 0.015789474     1 0.03010669 0.9897329 0.9789425 0.9481493 1.018672</span></span>
<span><span class="co">#&gt; 5 0.021052632     1 0.03029739 0.9827288 0.9732059 0.9409868 1.015363</span></span>
<span><span class="co">#&gt; 6 0.026315789     1 0.03112461 0.9753368 0.9670620 0.9338617 1.011553</span></span>
<span><span class="co">#&gt;            b5           b6           b7          b8           b9         b10</span></span>
<span><span class="co">#&gt; 1 0.014035790 -0.007461053 0.0185898207 0.021930913 -0.009900171 0.027401116</span></span>
<span><span class="co">#&gt; 2 0.003365848  0.000000000 0.0143413336 0.015434662 -0.007939397 0.022297378</span></span>
<span><span class="co">#&gt; 3 0.000000000  0.000000000 0.0096220251 0.010707434 -0.005256682 0.017464766</span></span>
<span><span class="co">#&gt; 4 0.000000000  0.000000000 0.0049333240 0.006364021 -0.002393492 0.012713145</span></span>
<span><span class="co">#&gt; 5 0.000000000  0.000000000 0.0001773114 0.002036028  0.000000000 0.007969742</span></span>
<span><span class="co">#&gt; 6 0.000000000  0.000000000 0.0000000000 0.000000000  0.000000000 0.003303730</span></span></code></pre>
<p>Benchmarking this approach results in:</p>
<pre><code><span><span class="co">#&gt; [1] 0.02515078 0.03008866 0.02273107 0.02360249 0.02436066</span></span></code></pre>
<p>So, we have reduced our run time even more!</p>
</div>
</div>
<div class="section level2">
<h2 id="the-third-approach-including-the-header-files">The third approach: Including the header files<a class="anchor" aria-label="anchor" href="#the-third-approach-including-the-header-files"></a>
</h2>
<p>This is, by far, the most difficult approach which is why we have
created a whole package to demonstrate it. You will find more
information in the vignette <code>The-optimizer-interface</code> and in
the <a href="https://github.com/jhorzek/lessLM" class="external-link">lessLM</a> package.</p>
<p>It will come to the same parameter estimates:</p>
<pre><code><span><span class="co">#&gt;              b0        b1        b2        b3       b4          b5           b6</span></span>
<span><span class="co">#&gt; [1,] 0.02734701 1.0129361 0.9991629 0.9705501 1.027728 0.013993181 -0.007491533</span></span>
<span><span class="co">#&gt; [2,] 0.02939675 1.0043635 0.9908681 0.9626493 1.025035 0.003400965  0.000000000</span></span>
<span><span class="co">#&gt; [3,] 0.02998680 0.9967117 0.9846504 0.9552960 1.021803 0.000000000  0.000000000</span></span>
<span><span class="co">#&gt; [4,] 0.03006777 0.9897315 0.9789595 0.9481301 1.018774 0.000000000  0.000000000</span></span>
<span><span class="co">#&gt; [5,] 0.03032345 0.9827556 0.9731799 0.9409662 1.015441 0.000000000  0.000000000</span></span>
<span><span class="co">#&gt; [6,] 0.03111085 0.9753325 0.9670615 0.9338506 1.011607 0.000000000  0.000000000</span></span>
<span><span class="co">#&gt;                b7          b8           b9         b10</span></span>
<span><span class="co">#&gt; [1,] 0.0186210155 0.021974963 -0.009975776 0.027466466</span></span>
<span><span class="co">#&gt; [2,] 0.0143089363 0.015388336 -0.007860992 0.022231196</span></span>
<span><span class="co">#&gt; [3,] 0.0095927088 0.010679371 -0.005183552 0.017406513</span></span>
<span><span class="co">#&gt; [4,] 0.0049636831 0.006397664 -0.002474334 0.012779758</span></span>
<span><span class="co">#&gt; [5,] 0.0001374354 0.002100692  0.000000000 0.008033475</span></span>
<span><span class="co">#&gt; [6,] 0.0000000000 0.000000000  0.000000000 0.003352431</span></span></code></pre>
<p>And the run times are even lower:</p>
<pre><code><span><span class="co">#&gt; [1] 0.003956079 0.002800226 0.002107382 0.002259731 0.002078533</span></span></code></pre>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Jannik H. Orzek.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
