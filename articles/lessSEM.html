<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="lessSEM">
<title>lessSEM • lessSEM</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="lessSEM">
<meta property="og:description" content="lessSEM">
<meta property="og:image" content="/logo.svg">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-dark navbar-expand-lg bg-primary"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">lessSEM</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">1.4.3</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item">
  <a class="nav-link" href="../articles/lessSEM.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/Definition-Variables-and-Multi-Group-SEM.html">Definition-Variables-and-Multi-Group-SEM</a>
    <a class="dropdown-item" href="../articles/General-Purpose-Optimization.html">General-Purpose-Optimization</a>
    <a class="dropdown-item" href="../articles/Mixed-Penalties.html">Mixed Penalties</a>
    <a class="dropdown-item" href="../articles/Parameter-transformations.html">Parameter-transformations</a>
    <a class="dropdown-item" href="../articles/SCAD-and-MCP.html">SCAD-and-MCP</a>
    <a class="dropdown-item" href="../articles/The-Structural-Equation-Model.html">The-Structural-Equation-Model</a>
    <a class="dropdown-item" href="../articles/The-optimizer-interface.html">The-optimizer-interface</a>
    <a class="dropdown-item" href="../articles/log-likelihood-gradients.html">log-likelihood-gradients</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.svg" class="logo" alt=""><h1>lessSEM</h1>
            
      
      
      <div class="d-none name"><code>lessSEM.Rmd</code></div>
    </div>

    
    
<div class="section level3">
<h3 id="regularized-structural-equation-modeling">Regularized Structural Equation Modeling<a class="anchor" aria-label="anchor" href="#regularized-structural-equation-modeling"></a>
</h3>
<p>Regularized structural equation modeling (REGSEM) has been proposed
by Jacobucci et al. (2016) and Huang et al. (2017). The objective is to
reduce overfitting in small samples and to allow for more flexibility.
The general idea is to regularize some parameters towards zero. To this
end, a penalty function <span class="math inline">\(p(\pmb\theta)\)</span> is added to the vanilla
objective function. In lessSEM, this objective function is given by the
full information maximum likelihood function <span class="math inline">\(F_{\text{ML}}(\pmb\theta)\)</span>. The new
objective function is defined as:</p>
<p><span class="math display">\[F_{\text{REGSEM},\lambda}(\pmb\theta) =
F_{\text{ML}}(\pmb\theta)+ \lambda N p(\pmb\theta)\]</span></p>
<ul>
<li>
<span class="math inline">\(F_{\text{ML}}(\pmb\theta)\)</span> wants
all parameters to be close to the ordinary maximum likelihood
estimates</li>
<li>
<span class="math inline">\(p(\pmb\theta)\)</span> wants regularized
parameters to be close to zero</li>
<li>
<span class="math inline">\(\lambda\)</span> allows us to fine tune
which of the two forces mentioned above gets more influence on the final
parameter estimates</li>
<li>
<span class="math inline">\(N\)</span> is the sample size. Scaling
with <span class="math inline">\(N\)</span> is done to stay consistent
with results returned by <strong>regsem</strong> and
<strong>lslx</strong>.</li>
</ul>
<p>There are many different penalty functions which could be used. In
<strong>lessSEM</strong>, we have implemented the following
functions:</p>
<p><span class="math display">\[
\begin{array}{l|ll}
\text{penalty} &amp; \text{function} &amp; \text{reference}\\
\hline
\text{ridge} &amp; p( x_j) = \lambda x_j^2 &amp; \text{(Hoerl &amp;
Kennard, 1970)}\\
\text{lasso} &amp; p( x_j) = \lambda| x_j| &amp; \text{(Tibshirani,
1996)}\\
\text{adaptiveLasso} &amp; p( x_j) = \frac{1}{w_j}\lambda| x_j| &amp;
\text{(Zou, 2006)}\\
\text{elasticNet} &amp; p( x_j) = \alpha\lambda|x_j| + (1-\alpha)\lambda
x_j^2 &amp; \text{(Zou &amp; Hastie, 2005)}\\
\text{cappedL1} &amp; p( x_j) = \lambda \min(| x_j|, \theta); \theta
&gt; 0 &amp; \text{(Zhang, 2010)}\\
\text{lsp} &amp; p( x_j) = \lambda \log(1 + |x_j|\theta); \theta &gt; 0
&amp; \text{(Candès et al., 2008)} \\
\text{scad} &amp; p( x_j) = \begin{cases}
\lambda |x_j| &amp; \text{if } |x_j| \leq \lambda\\
\frac{-x_j^2 + 2\theta\lambda |x_j| - \lambda^2}{2(\theta -1)} &amp;
\text{if } \lambda &lt; |x_j| \leq \lambda\theta \\
(\theta + 1) \lambda^2/2 &amp; \text{if } |x_j| \geq \theta\lambda\\
\end{cases}; \theta &gt; 2 &amp; \text{(Fan &amp; Li, 2001)} \\
\text{mcp} &amp; p( x_j) =
\begin{cases}
\lambda |x_j| - x_j^2/(2\theta) &amp; \text{if } |x_j| \leq
\theta\lambda\\
\theta\lambda^2/2 &amp; \text{if } |x_j| &gt; \lambda\theta
\end{cases}; \theta &gt; 0 &amp; \text{(Zhang, 2010)}
\end{array}
\]</span></p>
</div>
<div class="section level3">
<h3 id="objectives">Objectives<a class="anchor" aria-label="anchor" href="#objectives"></a>
</h3>
<p>The objectives of <strong>lessSEM</strong> are to provide …</p>
<ol style="list-style-type: decimal">
<li>a flexible framework for regularizing SEM and</li>
<li>optimizers for other SEM packages which can be used with an
interface similar to <code>optim</code>.</li>
</ol>
</div>
<div class="section level3">
<h3 id="regularizing-sem">Regularizing SEM<a class="anchor" aria-label="anchor" href="#regularizing-sem"></a>
</h3>
<p><strong>lessSEM</strong> is heavily inspired by the
<strong>regsem</strong> package. It also builds on
<strong>lavaan</strong> to set up the model.</p>
<div class="section level4">
<h4 id="setting-up-a-model">Setting up a model<a class="anchor" aria-label="anchor" href="#setting-up-a-model"></a>
</h4>
<p>First, start with lavaan:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://lavaan.ugent.be" class="external-link">lavaan</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; This is lavaan 0.6-14</span></span>
<span><span class="co">#&gt; lavaan is FREE software! Please report any bugs.</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va">lessSEM</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">4321</span><span class="op">)</span></span>
<span><span class="co"># let's simulate data for a simple </span></span>
<span><span class="co"># cfa with 7 observed variables</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu">lessSEM</span><span class="fu">::</span><span class="fu"><a href="../reference/simulateExampleData.html">simulateExampleData</a></span><span class="op">(</span>N <span class="op">=</span> <span class="fl">50</span>, </span>
<span>                                     loadings <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">4</span><span class="op">)</span>,</span>
<span>                                                  <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="co">#&gt;              y1         y2         y3         y4          y5         y6</span></span>
<span><span class="co">#&gt; [1,] -0.1737175 -0.1970204  1.1888412  1.8520403  0.16257957  1.8825526</span></span>
<span><span class="co">#&gt; [2,] -1.5179940  0.9029781 -0.1726986 -0.3596920 -0.02092956 -0.5798953</span></span>
<span><span class="co">#&gt; [3,]  0.6136418  0.2578986 -0.1359237  0.7703602  0.23502463  0.2001872</span></span>
<span><span class="co">#&gt; [4,] -0.5920933  0.2157830  1.6784758  1.8568433 -0.60458482  0.2219578</span></span>
<span><span class="co">#&gt; [5,]  0.0763996 -1.1442382 -2.8122156  0.4899892  0.03453494  2.0457604</span></span>
<span><span class="co">#&gt; [6,]  2.2504896  2.9742206  0.4353705  1.2338364  0.04693253 -0.6438847</span></span>
<span><span class="co">#&gt;              y7</span></span>
<span><span class="co">#&gt; [1,]  1.1383999</span></span>
<span><span class="co">#&gt; [2,]  0.9020861</span></span>
<span><span class="co">#&gt; [3,]  0.7986506</span></span>
<span><span class="co">#&gt; [4,]  0.4736751</span></span>
<span><span class="co">#&gt; [5,] -2.6721417</span></span>
<span><span class="co">#&gt; [6,] -1.1386235</span></span>
<span></span>
<span><span class="co"># we assume a single factor structure</span></span>
<span><span class="va">lavaanSyntax</span> <span class="op">&lt;-</span> <span class="st">"</span></span>
<span><span class="st">      f =~ l1*y1 + l2*y2 + l3*y3 + l4*y4 + l5*y5 + l6*y6 + l7*y7 </span></span>
<span><span class="st">      f ~~ 1*f</span></span>
<span><span class="st">      "</span></span>
<span><span class="co"># estimate the model with lavaan</span></span>
<span><span class="va">lavaanModel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lavaan/man/cfa.html" class="external-link">cfa</a></span><span class="op">(</span><span class="va">lavaanSyntax</span>, </span>
<span>                   data <span class="op">=</span> <span class="va">data</span><span class="op">)</span></span></code></pre></div>
<p>Next, decide which parameters should be regularized. Let’s go with
l5-l7. In <strong>lessSEM</strong>, we always use the parameter labels
to specify which parameters should be regularized!</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">regularized</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"l5"</span>, <span class="st">"l6"</span>, <span class="st">"l7"</span><span class="op">)</span></span>
<span><span class="co"># tip: we can use paste to make this easier:</span></span>
<span><span class="va">regularized</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/paste.html" class="external-link">paste0</a></span><span class="op">(</span><span class="st">"l"</span>, <span class="fl">5</span><span class="op">:</span><span class="fl">7</span><span class="op">)</span></span></code></pre></div>
<p>Finally, we set up the regularized model. To this end, we must first
decide which penalty function we want to use. If we want to shrink
parameters without setting them to zero, we can use ridge
regularization. Otherwise, we must use any of the other penalty
functions mentioned above. In <strong>lessSEM</strong>, there is a
dedicated function for each of these penalties. The names of these
functions are identical to the “penalty” column in the table above. For
instance, let’s have a look at the lasso penalty:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fitLasso</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/lasso.html">lasso</a></span><span class="op">(</span>lavaanModel <span class="op">=</span> <span class="va">lavaanModel</span>, </span>
<span>                  regularized <span class="op">=</span> <span class="va">regularized</span>,</span>
<span>                  nLambdas <span class="op">=</span> <span class="fl">5</span><span class="op">)</span></span></code></pre></div>
<p>Plot the paths to see what is going on:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fitLasso</span><span class="op">)</span></span></code></pre></div>
<p><img src="lessSEM_files/figure-html/unnamed-chunk-6-1.png" width="700"></p>
<p>Note that the parameters are pulled towards zero as <span class="math inline">\(\lambda\)</span> increases. Note also that we did
not specify specific values for <span class="math inline">\(\lambda\)</span> in the lasso function above.
Instead, we only specified how many <span class="math inline">\(\lambda\)</span>s we want to have
(<code>nLambdas=50</code>). If we use the lasso or adaptive lasso,
<strong>lessSEM</strong> can automatically compute which <span class="math inline">\(\lambda\)</span> is necessary to set all
parameters to zero. This is currently not supported for any of the other
penalties.</p>
<p>The plots returned by <strong>lessSEM</strong> are either
<strong>ggplot2</strong> elements (in case of a single tuning
parameter), or created with plotly (in case of 2 tuning parameters). You
can change a plot post-hoc:</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fitLasso</span><span class="op">)</span> <span class="op">+</span> <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html" class="external-link">theme_bw</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p><img src="lessSEM_files/figure-html/unnamed-chunk-7-1.png" width="700"></p>
<p>The <code>coef</code> function gives access to all parameter
estimates:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">fitLasso</span><span class="op">)</span></span>
<span><span class="co">#&gt;                                                                               </span></span>
<span><span class="co">#&gt;   Tuning         ||--||  Estimates                                            </span></span>
<span><span class="co">#&gt;  ------- ------- ||--|| ---------- ---------- ---------- ---------- ----------</span></span>
<span><span class="co">#&gt;   lambda   alpha ||--||         l2         l3         l4         l5         l6</span></span>
<span><span class="co">#&gt;  ======= ======= ||--|| ========== ========== ========== ========== ==========</span></span>
<span><span class="co">#&gt;   0.1034  1.0000 ||--||     0.7523     0.7536     0.5742          .          .</span></span>
<span><span class="co">#&gt;   0.0776  1.0000 ||--||     0.7477     0.7480     0.5720    -0.0104          .</span></span>
<span><span class="co">#&gt;   0.0517  1.0000 ||--||     0.7399     0.7396     0.5688    -0.0266          .</span></span>
<span><span class="co">#&gt;   0.0259  1.0000 ||--||     0.7301     0.7332     0.5677    -0.0418          .</span></span>
<span><span class="co">#&gt;   0.0000  1.0000 ||--||     0.7239     0.7318     0.5688    -0.0562     0.0166</span></span>
<span><span class="co">#&gt;                                                                              </span></span>
<span><span class="co">#&gt;                                                                              </span></span>
<span><span class="co">#&gt;  ---------- ---------- ---------- ---------- ---------- ---------- ----------</span></span>
<span><span class="co">#&gt;          l7     y1~~y1     y2~~y2     y3~~y3     y4~~y4     y5~~y5     y6~~y6</span></span>
<span><span class="co">#&gt;  ========== ========== ========== ========== ========== ========== ==========</span></span>
<span><span class="co">#&gt;           .     0.8812     1.1477     1.9274     1.0804     0.5710     0.9628</span></span>
<span><span class="co">#&gt;           .     0.8742     1.1523     1.9331     1.0818     0.5705     0.9628</span></span>
<span><span class="co">#&gt;     -0.0090     0.8632     1.1602     1.9416     1.0838     0.5697     0.9628</span></span>
<span><span class="co">#&gt;     -0.0479     0.8529     1.1706     1.9481     1.0841     0.5690     0.9628</span></span>
<span><span class="co">#&gt;     -0.0894     0.8491     1.1779     1.9496     1.0830     0.5685     0.9626</span></span>
<span><span class="co">#&gt;            </span></span>
<span><span class="co">#&gt;            </span></span>
<span><span class="co">#&gt;  ----------</span></span>
<span><span class="co">#&gt;      y7~~y7</span></span>
<span><span class="co">#&gt;  ==========</span></span>
<span><span class="co">#&gt;      1.5320</span></span>
<span><span class="co">#&gt;      1.5320</span></span>
<span><span class="co">#&gt;      1.5312</span></span>
<span><span class="co">#&gt;      1.5282</span></span>
<span><span class="co">#&gt;      1.5255</span></span></code></pre></div>
<p>Now, let’s assume you also want to try out the scad penalty. In this
case, all you have to do is to replace the <code><a href="../reference/lasso.html">lasso()</a></code> function
with the <code><a href="../reference/scad.html">scad()</a></code> function:</p>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fitScad</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/scad.html">scad</a></span><span class="op">(</span>lavaanModel <span class="op">=</span> <span class="va">lavaanModel</span>, </span>
<span>                regularized <span class="op">=</span> <span class="va">regularized</span>,</span>
<span>                lambdas <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span>,length.out <span class="op">=</span> <span class="fl">4</span><span class="op">)</span>,</span>
<span>                thetas <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">2.1</span>, <span class="fl">5</span>,length.out <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>The scad penalty has two tuning parmeters <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\theta\)</span>. The naming follows that used by
Gong et al. (2013). We can plot the results again, however this requires
the <strong>plotly</strong> package and is currently not supported in
Rmarkdown.</p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">fitScad</span><span class="op">)</span></span></code></pre></div>
<p>The parameter estimates can again be accessed with the
<code><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef()</a></code> function:</p>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">fitScad</span><span class="op">)</span></span>
<span><span class="co">#&gt;                                                                               </span></span>
<span><span class="co">#&gt;   Tuning         ||--||  Estimates                                            </span></span>
<span><span class="co">#&gt;  ------- ------- ||--|| ---------- ---------- ---------- ---------- ----------</span></span>
<span><span class="co">#&gt;   lambda   theta ||--||         l2         l3         l4         l5         l6</span></span>
<span><span class="co">#&gt;  ======= ======= ||--|| ========== ========== ========== ========== ==========</span></span>
<span><span class="co">#&gt;   0.0000  2.1000 ||--||     0.7240     0.7320     0.5689    -0.0562     0.0166</span></span>
<span><span class="co">#&gt;   0.3333  2.1000 ||--||     0.7520     0.7533     0.5741          .          .</span></span>
<span><span class="co">#&gt;   0.6667  2.1000 ||--||     0.7522     0.7535     0.5742          .          .</span></span>
<span><span class="co">#&gt;   1.0000  2.1000 ||--||     0.7523     0.7536     0.5742          .          .</span></span>
<span><span class="co">#&gt;   0.0000  5.0000 ||--||     0.7244     0.7326     0.5690    -0.0561     0.0167</span></span>
<span><span class="co">#&gt;   0.3333  5.0000 ||--||     0.7520     0.7533     0.5741          .          .</span></span>
<span><span class="co">#&gt;   0.6667  5.0000 ||--||     0.7522     0.7535     0.5742          .          .</span></span>
<span><span class="co">#&gt;   1.0000  5.0000 ||--||     0.7523     0.7536     0.5742          .          .</span></span>
<span><span class="co">#&gt;                                                                              </span></span>
<span><span class="co">#&gt;                                                                              </span></span>
<span><span class="co">#&gt;  ---------- ---------- ---------- ---------- ---------- ---------- ----------</span></span>
<span><span class="co">#&gt;          l7     y1~~y1     y2~~y2     y3~~y3     y4~~y4     y5~~y5     y6~~y6</span></span>
<span><span class="co">#&gt;  ========== ========== ========== ========== ========== ========== ==========</span></span>
<span><span class="co">#&gt;     -0.0894     0.8492     1.1778     1.9495     1.0829     0.5684     0.9626</span></span>
<span><span class="co">#&gt;           .     0.8808     1.1480     1.9277     1.0804     0.5710     0.9628</span></span>
<span><span class="co">#&gt;           .     0.8812     1.1478     1.9274     1.0804     0.5710     0.9628</span></span>
<span><span class="co">#&gt;           .     0.8812     1.1478     1.9274     1.0804     0.5710     0.9628</span></span>
<span><span class="co">#&gt;     -0.0894     0.8499     1.1774     1.9489     1.0828     0.5685     0.9626</span></span>
<span><span class="co">#&gt;           .     0.8808     1.1480     1.9277     1.0804     0.5710     0.9628</span></span>
<span><span class="co">#&gt;           .     0.8812     1.1478     1.9274     1.0804     0.5710     0.9628</span></span>
<span><span class="co">#&gt;           .     0.8812     1.1478     1.9274     1.0804     0.5710     0.9628</span></span>
<span><span class="co">#&gt;            </span></span>
<span><span class="co">#&gt;            </span></span>
<span><span class="co">#&gt;  ----------</span></span>
<span><span class="co">#&gt;      y7~~y7</span></span>
<span><span class="co">#&gt;  ==========</span></span>
<span><span class="co">#&gt;      1.5255</span></span>
<span><span class="co">#&gt;      1.5320</span></span>
<span><span class="co">#&gt;      1.5320</span></span>
<span><span class="co">#&gt;      1.5320</span></span>
<span><span class="co">#&gt;      1.5255</span></span>
<span><span class="co">#&gt;      1.5320</span></span>
<span><span class="co">#&gt;      1.5320</span></span>
<span><span class="co">#&gt;      1.5320</span></span></code></pre></div>
</div>
<div class="section level4">
<h4 id="selecting-a-model">Selecting a model<a class="anchor" aria-label="anchor" href="#selecting-a-model"></a>
</h4>
<p>To select a model and report the final parameter estimates, you can
use the AIC or BIC (other information criteria are also possible, but
currently not implemented). There are two ways to use these information
criteria.</p>
<p>First, you can compute them and select the model yourself:</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">AICs</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/AIC.html" class="external-link">AIC</a></span><span class="op">(</span><span class="va">fitLasso</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">AICs</span><span class="op">)</span></span>
<span><span class="co">#&gt;       lambda alpha     m2LL  regM2LL nonZeroParameters convergence      AIC</span></span>
<span><span class="co">#&gt; 1 0.10340364     1 1071.078 1071.078                10        TRUE 1091.078</span></span>
<span><span class="co">#&gt; 2 0.07755273     1 1071.033 1071.074                11        TRUE 1093.033</span></span>
<span><span class="co">#&gt; 3 0.05170182     1 1070.956 1071.048                12        TRUE 1094.956</span></span>
<span><span class="co">#&gt; 4 0.02585091     1 1070.851 1070.967                12        TRUE 1094.851</span></span>
<span><span class="co">#&gt; 5 0.00000000     1 1070.810 1070.810                13        TRUE 1096.810</span></span>
<span></span>
<span><span class="va">fitLasso</span><span class="op">@</span><span class="va">parameters</span><span class="op">[</span><span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.min</a></span><span class="op">(</span><span class="va">AICs</span><span class="op">$</span><span class="va">AIC</span><span class="op">)</span>,<span class="op">]</span></span>
<span><span class="co">#&gt;      lambda alpha        l2        l3       l4 l5 l6 l7    y1~~y1   y2~~y2</span></span>
<span><span class="co">#&gt; 1 0.1034036     1 0.7522981 0.7536087 0.574216  0  0  0 0.8812245 1.147738</span></span>
<span><span class="co">#&gt;     y3~~y3   y4~~y4    y5~~y5    y6~~y6   y7~~y7</span></span>
<span><span class="co">#&gt; 1 1.927356 1.080356 0.5710042 0.9628056 1.531997</span></span></code></pre></div>
<p>An easier way is to use the <code><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef()</a></code> function again:</p>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">fitLasso</span>, criterion <span class="op">=</span> <span class="st">"AIC"</span><span class="op">)</span></span>
<span><span class="co">#&gt;                                                                               </span></span>
<span><span class="co">#&gt;   Tuning         ||--||  Estimates                                            </span></span>
<span><span class="co">#&gt;  ------- ------- ||--|| ---------- ---------- ---------- ---------- ----------</span></span>
<span><span class="co">#&gt;   lambda   alpha ||--||         l2         l3         l4         l5         l6</span></span>
<span><span class="co">#&gt;  ======= ======= ||--|| ========== ========== ========== ========== ==========</span></span>
<span><span class="co">#&gt;   0.1034  1.0000 ||--||     0.7523     0.7536     0.5742          .          .</span></span>
<span><span class="co">#&gt;                                                                              </span></span>
<span><span class="co">#&gt;                                                                              </span></span>
<span><span class="co">#&gt;  ---------- ---------- ---------- ---------- ---------- ---------- ----------</span></span>
<span><span class="co">#&gt;          l7     y1~~y1     y2~~y2     y3~~y3     y4~~y4     y5~~y5     y6~~y6</span></span>
<span><span class="co">#&gt;  ========== ========== ========== ========== ========== ========== ==========</span></span>
<span><span class="co">#&gt;           .     0.8812     1.1477     1.9274     1.0804     0.5710     0.9628</span></span>
<span><span class="co">#&gt;            </span></span>
<span><span class="co">#&gt;            </span></span>
<span><span class="co">#&gt;  ----------</span></span>
<span><span class="co">#&gt;      y7~~y7</span></span>
<span><span class="co">#&gt;  ==========</span></span>
<span><span class="co">#&gt;      1.5320</span></span></code></pre></div>
<div class="section level5">
<h5 id="cross-validation">Cross-Validation<a class="anchor" aria-label="anchor" href="#cross-validation"></a>
</h5>
<p>A very good alternative to information criteria is the use of
cross-validation. In <strong>lessSEM</strong>, there is a dedicated
cross-validation function for each of the penalties discussed above.
Let’s look at the <code><a href="../reference/lsp.html">lsp()</a></code> penalty this time. Now, for your
non-cross-validated lsp, you would use</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fitLsp</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/lsp.html">lsp</a></span><span class="op">(</span>lavaanModel <span class="op">=</span> <span class="va">lavaanModel</span>, </span>
<span>              regularized <span class="op">=</span> <span class="va">regularized</span>,</span>
<span>              lambdas <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">.1</span><span class="op">)</span>,</span>
<span>              thetas <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">.1</span>,<span class="fl">2</span>,length.out <span class="op">=</span> <span class="fl">4</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>To use a cross-validated version of the lsp, simply use the
<code>cv</code> prefix. The function is called <code><a href="../reference/cvLsp.html">cvLsp()</a></code>:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fitCvLsp</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/cvLsp.html">cvLsp</a></span><span class="op">(</span>lavaanModel <span class="op">=</span> <span class="va">lavaanModel</span>, </span>
<span>                  regularized <span class="op">=</span> <span class="va">regularized</span>,</span>
<span>                  lambdas <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">.1</span><span class="op">)</span>,</span>
<span>                  thetas <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">.1</span>,<span class="fl">2</span>,length.out <span class="op">=</span> <span class="fl">4</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>The best model can now be accessed with</p>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">fitCvLsp</span><span class="op">)</span></span>
<span><span class="co">#&gt;                                                                               </span></span>
<span><span class="co">#&gt;   Tuning         ||--||  Estimates                                            </span></span>
<span><span class="co">#&gt;  ------- ------- ||--|| ---------- ---------- ---------- ---------- ----------</span></span>
<span><span class="co">#&gt;   lambda   theta ||--||         l2         l3         l4         l5         l6</span></span>
<span><span class="co">#&gt;  ======= ======= ||--|| ========== ========== ========== ========== ==========</span></span>
<span><span class="co">#&gt;   1.0000  0.1000 ||--||     0.7520     0.7533     0.5741          .          .</span></span>
<span><span class="co">#&gt;                                                                              </span></span>
<span><span class="co">#&gt;                                                                              </span></span>
<span><span class="co">#&gt;  ---------- ---------- ---------- ---------- ---------- ---------- ----------</span></span>
<span><span class="co">#&gt;          l7     y1~~y1     y2~~y2     y3~~y3     y4~~y4     y5~~y5     y6~~y6</span></span>
<span><span class="co">#&gt;  ========== ========== ========== ========== ========== ========== ==========</span></span>
<span><span class="co">#&gt;           .     0.8808     1.1480     1.9277     1.0804     0.5710     0.9628</span></span>
<span><span class="co">#&gt;            </span></span>
<span><span class="co">#&gt;            </span></span>
<span><span class="co">#&gt;  ----------</span></span>
<span><span class="co">#&gt;      y7~~y7</span></span>
<span><span class="co">#&gt;  ==========</span></span>
<span><span class="co">#&gt;      1.5320</span></span></code></pre></div>
</div>
</div>
<div class="section level4">
<h4 id="missing-data">Missing Data<a class="anchor" aria-label="anchor" href="#missing-data"></a>
</h4>
<p>Most psychological data sets will have missing data. In
<strong>lessSEM</strong>, we follow the example of
<strong>regsem</strong> and use the full information maximum likelihood
function to account for this missingness. Identical to
<strong>regsem</strong>, <strong>lessSEM</strong> expects that you
already use the full information maximum likelihood method in
<strong>lavaan</strong>.</p>
<div class="sourceCode" id="cb15"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># let's simulate data for a simple </span></span>
<span><span class="co"># cfa with 7 observed variables</span></span>
<span><span class="co"># and 10 % missing data</span></span>
<span><span class="va">data</span> <span class="op">&lt;-</span> <span class="fu">lessSEM</span><span class="fu">::</span><span class="fu"><a href="../reference/simulateExampleData.html">simulateExampleData</a></span><span class="op">(</span>N <span class="op">=</span> <span class="fl">100</span>, </span>
<span>                                     loadings <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">4</span><span class="op">)</span>,</span>
<span>                                                  <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">3</span><span class="op">)</span><span class="op">)</span>,</span>
<span>                                     percentMissing <span class="op">=</span> <span class="fl">10</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">head</a></span><span class="op">(</span><span class="va">data</span><span class="op">)</span></span>
<span><span class="co">#&gt;               y1         y2         y3          y4         y5        y6</span></span>
<span><span class="co">#&gt; [1,]  0.60367543 -0.3206755 -0.5712115  0.36626658  0.6138552 0.8207451</span></span>
<span><span class="co">#&gt; [2,]  0.37497661  2.0100766 -1.5925242 -0.02983920  0.2409065 1.1250778</span></span>
<span><span class="co">#&gt; [3,]          NA  0.8134143  1.7803075  3.27710938 -0.3651732        NA</span></span>
<span><span class="co">#&gt; [4,] -0.04379503  0.1369219 -1.9424719  0.40304282 -0.6435542 1.5412868</span></span>
<span><span class="co">#&gt; [5,] -0.32969221         NA -1.6536493 -2.20991516  1.2462449 0.6725163</span></span>
<span><span class="co">#&gt; [6,]  0.61738032  0.9116425  0.9196841  0.03340633  0.5553805 0.1209500</span></span>
<span><span class="co">#&gt;              y7</span></span>
<span><span class="co">#&gt; [1,]  0.6346473</span></span>
<span><span class="co">#&gt; [2,]  0.8865902</span></span>
<span><span class="co">#&gt; [3,] -0.8283463</span></span>
<span><span class="co">#&gt; [4,]  0.0635044</span></span>
<span><span class="co">#&gt; [5,]         NA</span></span>
<span><span class="co">#&gt; [6,]  2.0956358</span></span>
<span></span>
<span><span class="co"># we assume a single factor structure</span></span>
<span><span class="va">lavaanSyntax</span> <span class="op">&lt;-</span> <span class="st">"</span></span>
<span><span class="st">      f =~ l1*y1 + l2*y2 + l3*y3 + l4*y4 + l5*y5 + l6*y6 + l7*y7 </span></span>
<span><span class="st">      f ~~ 1*f</span></span>
<span><span class="st">      "</span></span>
<span><span class="co"># estimate the model with lavaan</span></span>
<span><span class="va">lavaanModel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lavaan/man/cfa.html" class="external-link">cfa</a></span><span class="op">(</span><span class="va">lavaanSyntax</span>, </span>
<span>                   data <span class="op">=</span> <span class="va">data</span>,</span>
<span>                   missing <span class="op">=</span> <span class="st">"ml"</span><span class="op">)</span> <span class="co"># important: use fiml for missing data</span></span></code></pre></div>
<p>Note that we added the argument <code>missing = 'ml'</code> to the
<strong>lavaan</strong> model. This tells <strong>lavaan</strong> to use
the full information maximum likelihood function.</p>
<p>Next, pass this model to any of the penalty functions in
<strong>lessSEM</strong>. <strong>lessSEM</strong> will automatically
switch to the full information maximum likelihood function as well:</p>
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fitLasso</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/lasso.html">lasso</a></span><span class="op">(</span>lavaanModel <span class="op">=</span> <span class="va">lavaanModel</span>, </span>
<span>                  regularized <span class="op">=</span> <span class="va">regularized</span>,</span>
<span>                  nLambdas <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<p>To check if <strong>lessSEM</strong> did actually use the full
information maximum likelihood, we can compare the 2log-likelihood of
<strong>lavaan</strong> and <strong>lessSEM</strong> when no penalty is
used (<span class="math inline">\(\lambda = 0\)</span>):</p>
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fitLasso</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/lasso.html">lasso</a></span><span class="op">(</span>lavaanModel <span class="op">=</span> <span class="va">lavaanModel</span>, </span>
<span>                  regularized <span class="op">=</span> <span class="va">regularized</span>,</span>
<span>                  lambdas <span class="op">=</span> <span class="fl">0</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fitLasso</span><span class="op">@</span><span class="va">fits</span><span class="op">$</span><span class="va">m2LL</span></span>
<span><span class="co">#&gt; [1] 2034.104</span></span></code></pre></div>
<p>Compare this to:</p>
<div class="sourceCode" id="cb19"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">-</span><span class="fl">2</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/stats/logLik.html" class="external-link">logLik</a></span><span class="op">(</span><span class="va">lavaanModel</span><span class="op">)</span></span>
<span><span class="co">#&gt; 'log Lik.' 2034.104 (df=20)</span></span></code></pre></div>
</div>
</div>
<div class="section level3">
<h3 id="using-multiple-cores">Using multiple cores<a class="anchor" aria-label="anchor" href="#using-multiple-cores"></a>
</h3>
<p>By default, <strong>lessSEM</strong> will only use one computer core.
However, if a model has many parameters, parallel computations can be
considerably faster. Multi-Core support is therefore provided using the
<strong>RcppParallel</strong> package (Allaire et. al, 2023). To make
use of multiple cores, the number of cores must be specified in the
<code>control</code> argument (see below). Before doing that, it makes
sense to check how many cores the computer has:</p>
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://rcppcore.github.io/RcppParallel/" class="external-link">RcppParallel</a></span><span class="op">)</span></span>
<span><span class="co"># Print the number of threads (we call them cores for simplicity, but technically they are threads)</span></span>
<span><span class="fu">RcppParallel</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/RcppParallel/man/setThreadOptions.html" class="external-link">defaultNumThreads</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 2</span></span></code></pre></div>
<p>Note that using all cores can block the computer because there are no
resources left for other tasks than R. To use 2 cores, we can set
<code>nCores = 2</code> as follows:</p>
<div class="sourceCode" id="cb21"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fitLasso</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/lasso.html">lasso</a></span><span class="op">(</span>lavaanModel <span class="op">=</span> <span class="va">lavaanModel</span>, </span>
<span>                  regularized <span class="op">=</span> <span class="va">regularized</span>,</span>
<span>                  nLambdas <span class="op">=</span> <span class="fl">10</span>,</span>
<span>                  control <span class="op">=</span> <span class="fu"><a href="../reference/controlGlmnet.html">controlGlmnet</a></span><span class="op">(</span>nCores <span class="op">=</span> <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Note that multi-core support is only provided for SEM. Using the
optimizers implemented in <strong>lessSEM</strong> for models other than
SEM (e.g., in the <a href="https://github.com/jhorzek/lessLM" class="external-link"><strong>lessLM</strong></a>
package) will not automatically allow for multi-core execution.</p>
</div>
<div class="section level3">
<h3 id="changing-the-optimizer">Changing the optimizer<a class="anchor" aria-label="anchor" href="#changing-the-optimizer"></a>
</h3>
<p><strong>lessSEM</strong> comes with two specialized optimization
procedures for elastic-net-type penalties: ista and glmnet. Currently,
the default is glmnet for all elastic net variants (ridge, lasso,
adaptive lasso, elastic net) and ista for all other penalties. Ista does
not require the computation of a Hessian matrix. However, this comes at
a price: ista optimization tends to call the fit and gradient function a
lot more than glment. If you are using an elastic-net-type penalty
(ridge, lasso, adaptive lasso, or elastic net), we recommend that you
first test the glmnet optimizer and then switch to ista if glmnet
results in errors due to the Hessian matrix. Switching to ista is done
as follows:</p>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fitLasso</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/lasso.html">lasso</a></span><span class="op">(</span>lavaanModel <span class="op">=</span> <span class="va">lavaanModel</span>, </span>
<span>                  regularized <span class="op">=</span> <span class="va">regularized</span>,</span>
<span>                  nLambdas <span class="op">=</span> <span class="fl">10</span>,</span>
<span>                  method <span class="op">=</span> <span class="st">"ista"</span>, <span class="co"># change the method</span></span>
<span>                  control <span class="op">=</span> <span class="fu"><a href="../reference/controlIsta.html">controlIsta</a></span><span class="op">(</span><span class="op">)</span> <span class="co"># change the control argument</span></span>
<span>                  <span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="parameter-transformations">Parameter transformations<a class="anchor" aria-label="anchor" href="#parameter-transformations"></a>
</h3>
<p><strong>lessSEM</strong> allows for parameter transformations. This
is explained in detail in the vignette Parameter-transformations (see
<code><a href="../articles/Parameter-transformations.html">vignette("Parameter-transformations", package = "lessSEM")</a></code>).
To provide a short example, let’s have a look at the political democracy
data set:</p>
<div class="sourceCode" id="cb23"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># example from ?lavaan::sem</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://lavaan.ugent.be" class="external-link">lavaan</a></span><span class="op">)</span></span>
<span><span class="va">modelSyntax</span> <span class="op">&lt;-</span> <span class="st">' </span></span>
<span><span class="st">  # latent variable definitions</span></span>
<span><span class="st">     ind60 =~ x1 + x2 + x3</span></span>
<span><span class="st">     dem60 =~ y1 + a*y2 + b*y3 + c*y4</span></span>
<span><span class="st">     dem65 =~ y5 + a*y6 + b*y7 + c*y8</span></span>
<span><span class="st"></span></span>
<span><span class="st">  # regressions</span></span>
<span><span class="st">    dem60 ~ ind60</span></span>
<span><span class="st">    dem65 ~ ind60 + dem60</span></span>
<span><span class="st"></span></span>
<span><span class="st">  # residual correlations</span></span>
<span><span class="st">    y1 ~~ y5</span></span>
<span><span class="st">    y2 ~~ y4 </span></span>
<span><span class="st">    y3 ~~ y7</span></span>
<span><span class="st">    y4 ~~ y8</span></span>
<span><span class="st">    y6 ~~ y8</span></span>
<span><span class="st">'</span></span>
<span></span>
<span><span class="va">lavaanFit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lavaan/man/sem.html" class="external-link">sem</a></span><span class="op">(</span>model <span class="op">=</span> <span class="va">modelSyntax</span>,</span>
<span>                 data <span class="op">=</span> <span class="va">PoliticalDemocracy</span><span class="op">)</span></span></code></pre></div>
<p>Note that in the model estimated above, loadings on the latent
variables are constrained to equality over time. We could also relax
this assumption by allowing for time point specific loadings:</p>
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://lavaan.ugent.be" class="external-link">lavaan</a></span><span class="op">)</span></span>
<span><span class="va">modelSyntax</span> <span class="op">&lt;-</span> <span class="st">' </span></span>
<span><span class="st">  # latent variable definitions</span></span>
<span><span class="st">     ind60 =~ x1 + x2 + x3</span></span>
<span><span class="st">     dem60 =~ y1 + a1*y2 + b1*y3 + c1*y4</span></span>
<span><span class="st">     dem65 =~ y5 + a2*y6 + b2*y7 + c2*y8</span></span>
<span><span class="st"></span></span>
<span><span class="st">  # regressions</span></span>
<span><span class="st">    dem60 ~ ind60</span></span>
<span><span class="st">    dem65 ~ ind60 + dem60</span></span>
<span><span class="st"></span></span>
<span><span class="st">  # residual correlations</span></span>
<span><span class="st">    y1 ~~ y5</span></span>
<span><span class="st">    y2 ~~ y4 </span></span>
<span><span class="st">    y3 ~~ y7</span></span>
<span><span class="st">    y4 ~~ y8</span></span>
<span><span class="st">    y6 ~~ y8</span></span>
<span><span class="st">'</span></span>
<span></span>
<span><span class="va">lavaanFit</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lavaan/man/sem.html" class="external-link">sem</a></span><span class="op">(</span>model <span class="op">=</span> <span class="va">modelSyntax</span>,</span>
<span>                 data <span class="op">=</span> <span class="va">PoliticalDemocracy</span><span class="op">)</span></span></code></pre></div>
<p>Deciding between both approaches can be difficult as there may be
some parameters for which equality over time holds, while others violate
the assumption. Here, transformations can be used to regularize
differences between parameters. To this end, we define the
transformations:</p>
<div class="sourceCode" id="cb25"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">transformations</span> <span class="op">&lt;-</span> <span class="st">"</span></span>
<span><span class="st">// IMPORTANT: Our transformations always have to start with the follwing line:</span></span>
<span><span class="st">parameters: a1, a2, b1, b2, c1, c2, delta_a2, delta_b2, delta_c2</span></span>
<span><span class="st"></span></span>
<span><span class="st">// In the line above, we defined the names of the parameters which we</span></span>
<span><span class="st">// want to use in our transformations. EACH AND EVERY PARAMETER USED IN</span></span>
<span><span class="st">// THE FOLLOWING MUST BE STATED ABOVE. The line must always start with</span></span>
<span><span class="st">// the keyword 'parameters' followed by a colon. The parameters must be</span></span>
<span><span class="st">// separated by commata.</span></span>
<span><span class="st">// Comments are added with double-backslash</span></span>
<span><span class="st"></span></span>
<span><span class="st">// Now we can state our transformations:</span></span>
<span><span class="st"></span></span>
<span><span class="st">a2 = a1 + delta_a2; // statements must end with semicolon</span></span>
<span><span class="st">b2 = b1 + delta_b2;</span></span>
<span><span class="st">c2 = c1 + delta_c2;</span></span>
<span><span class="st">"</span></span></code></pre></div>
<p>Next, we have to pass the <code>transformations</code> variable to
the penalty function:</p>
<p>To check if measurement invariance can be assumed, we can select the
best model using information criteria:</p>
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">lassoFit</span>, criterion <span class="op">=</span> <span class="st">"BIC"</span><span class="op">)</span></span>
<span><span class="co">#&gt;                                                                               </span></span>
<span><span class="co">#&gt;   Tuning         ||--||  Estimates                                            </span></span>
<span><span class="co">#&gt;  ------- ------- ||--|| ---------- ---------- ---------- ---------- ----------</span></span>
<span><span class="co">#&gt;   lambda   alpha ||--||  ind60=~x2  ind60=~x3         a1         b1         c1</span></span>
<span><span class="co">#&gt;  ======= ======= ||--|| ========== ========== ========== ========== ==========</span></span>
<span><span class="co">#&gt;   0.2216  1.0000 ||--||     2.1825     1.8189     1.2110     1.1679     1.2340</span></span>
<span><span class="co">#&gt;                                                                      </span></span>
<span><span class="co">#&gt;                                                                      </span></span>
<span><span class="co">#&gt;  ----------- ----------- ----------- ---------- ---------- ----------</span></span>
<span><span class="co">#&gt;  dem60~ind60 dem65~ind60 dem65~dem60     y1~~y5     y2~~y4     y3~~y7</span></span>
<span><span class="co">#&gt;  =========== =========== =========== ========== ========== ==========</span></span>
<span><span class="co">#&gt;       1.4534      0.5935      0.8659     0.5552     1.5947     0.7807</span></span>
<span><span class="co">#&gt;                                                                              </span></span>
<span><span class="co">#&gt;                                                                              </span></span>
<span><span class="co">#&gt;  ---------- ---------- ---------- ---------- ---------- ---------- ----------</span></span>
<span><span class="co">#&gt;      y4~~y8     y6~~y8     x1~~x1     x2~~x2     x3~~x3     y1~~y1     y2~~y2</span></span>
<span><span class="co">#&gt;  ========== ========== ========== ========== ========== ========== ==========</span></span>
<span><span class="co">#&gt;      0.6537     1.5350     0.0820     0.1177     0.4675     1.7929     7.3843</span></span>
<span><span class="co">#&gt;                                                                                </span></span>
<span><span class="co">#&gt;                                                                                </span></span>
<span><span class="co">#&gt;  ---------- ---------- ---------- ---------- ---------- ---------- ------------</span></span>
<span><span class="co">#&gt;      y3~~y3     y4~~y4     y5~~y5     y6~~y6     y7~~y7     y8~~y8 ind60~~ind60</span></span>
<span><span class="co">#&gt;  ========== ========== ========== ========== ========== ========== ============</span></span>
<span><span class="co">#&gt;      5.0175     3.4074     2.2857     4.8977     3.5510     3.4511       0.4480</span></span>
<span><span class="co">#&gt;                                                            </span></span>
<span><span class="co">#&gt;                                                            </span></span>
<span><span class="co">#&gt;  ------------ ------------ ---------- ---------- ----------</span></span>
<span><span class="co">#&gt;  dem60~~dem60 dem65~~dem65   delta_a2   delta_b2   delta_c2</span></span>
<span><span class="co">#&gt;  ============ ============ ========== ========== ==========</span></span>
<span><span class="co">#&gt;        3.9408       0.2034          .          .          .</span></span></code></pre></div>
<p>More details are provided in
<code><a href="../articles/Parameter-transformations.html">vignette("Parameter-transformations", package = "lessSEM")</a></code>.</p>
</div>
<div class="section level2">
<h2 id="experimental-features">Experimental Features<a class="anchor" aria-label="anchor" href="#experimental-features"></a>
</h2>
<p>The following features are relatively new and you may still
experience some bugs. Please be aware of that when using these
features.</p>
<div class="section level3">
<h3 id="from-lesssem-to-lavaan">From <strong>lessSEM</strong> to <strong>lavaan</strong><a class="anchor" aria-label="anchor" href="#from-lesssem-to-lavaan"></a>
</h3>
<p><strong>lessSEM</strong> supports exporting specific models to
<strong>lavaan</strong>. This can be very useful when plotting the final
model. In our case, the best model is given by:</p>
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lambdaBest</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">rsem</span>, criterion <span class="op">=</span> <span class="st">"BIC"</span><span class="op">)</span><span class="op">$</span><span class="va">lambda</span> </span></code></pre></div>
<p>We can get the <strong>lavaan</strong> model with the parameters
corresponding to those of the regularized model with
<code>lambda = lambdaBest</code> as follows:</p>
<div class="sourceCode" id="cb28"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">lavaanModel</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/lessSEM2Lavaan.html">lessSEM2Lavaan</a></span><span class="op">(</span>regularizedSEM <span class="op">=</span> <span class="va">rsem</span>, </span>
<span>                              lambda <span class="op">=</span> <span class="va">lambdaBest</span><span class="op">)</span></span></code></pre></div>
<p>The result can be plotted with, for instance, <a href="https://github.com/SachaEpskamp/semPlot" class="external-link"><strong>semPlot</strong></a>:</p>
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/SachaEpskamp/semPlot" class="external-link">semPlot</a></span><span class="op">)</span></span>
<span><span class="fu">semPaths</span><span class="op">(</span><span class="va">lavaanModel</span>,</span>
<span>         what <span class="op">=</span> <span class="st">"est"</span>,</span>
<span>         fade <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level3">
<h3 id="multi-group-models-and-definition-variables">Multi-Group Models and Definition Variables<a class="anchor" aria-label="anchor" href="#multi-group-models-and-definition-variables"></a>
</h3>
<p><strong>lessSEM</strong> supports multi-group SEM and, to some
degree, definition variables. Regularized multi-group SEM have been
proposed by Huang (2018) and are implemented in <strong>lslx</strong>
(Huang, 2020). Here, differences between groups are regularized. A
detailed introduction can be found in
<code><a href="../articles/Definition-Variables-and-Multi-Group-SEM.html">vignette(topic = "Definition-Variables-and-Multi-Group-SEM", package = "lessSEM")</a></code>.
Therein it is also explained how the multi-group SEM can be used to
implement definition variables (e.g., for latent growth curve
models).</p>
</div>
<div class="section level3">
<h3 id="mixed-penalties">Mixed Penalties<a class="anchor" aria-label="anchor" href="#mixed-penalties"></a>
</h3>
<p><strong>lessSEM</strong> allows for defining different penalties for
different parts of the model. This feature is new and very experimental.
Please keep that in mind when using the procedure. A detailed
introduction can be found in
<code><a href="../articles/Mixed-Penalties.html">vignette(topic = "Mixed-Penalties", package = "lessSEM")</a></code>.</p>
<p>To provide a short example, we will regularize the loadings and the
regression parameters of the Political Democracy data set with different
penalties. The following script is adapted from
<code><a href="https://rdrr.io/pkg/lavaan/man/sem.html" class="external-link">?lavaan::sem</a></code>.</p>
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="st">' </span></span>
<span><span class="st">  # latent variable definitions</span></span>
<span><span class="st">     ind60 =~ x1 + x2 + x3 + c2*y2 + c3*y3 + c4*y4</span></span>
<span><span class="st">     dem60 =~ y1 + y2 + y3 + y4</span></span>
<span><span class="st">     dem65 =~ y5 + y6 + y7 + c*y8</span></span>
<span><span class="st"></span></span>
<span><span class="st">  # regressions</span></span>
<span><span class="st">    dem60 ~ r1*ind60</span></span>
<span><span class="st">    dem65 ~ r2*ind60 + r3*dem60</span></span>
<span><span class="st">'</span></span>
<span></span>
<span><span class="va">lavaanModel</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/lavaan/man/sem.html" class="external-link">sem</a></span><span class="op">(</span><span class="va">model</span>,</span>
<span>                   data <span class="op">=</span> <span class="va">PoliticalDemocracy</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># Let's add a lasso penalty on the cross-loadings c2 - c4 and </span></span>
<span><span class="co"># scad penalty on the regressions r1-r3</span></span>
<span><span class="va">mp</span> <span class="op">&lt;-</span> <span class="va">lavaanModel</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/mixedPenalty.html">mixedPenalty</a></span><span class="op">(</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/addLasso.html">addLasso</a></span><span class="op">(</span>regularized <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"c2"</span>, <span class="st">"c3"</span>, <span class="st">"c4"</span><span class="op">)</span>, </span>
<span>           lambdas <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">.1</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/addLasso.html">addLasso</a></span><span class="op">(</span>regularized <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"r1"</span>, <span class="st">"r2"</span>, <span class="st">"r3"</span><span class="op">)</span>, </span>
<span>           lambdas <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">1</span>,<span class="fl">.2</span><span class="op">)</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="../reference/fit.html">fit</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>The best model according to the BIC can be extracted with:</p>
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html" class="external-link">coef</a></span><span class="op">(</span><span class="va">fitMp</span>, criterion <span class="op">=</span> <span class="st">"BIC"</span><span class="op">)</span></span></code></pre></div>
</div>
</div>
<div class="section level2">
<h2 id="more-information">More information<a class="anchor" aria-label="anchor" href="#more-information"></a>
</h2>
<p>We provide more information in the documentation of the individual
functions. For instance, see <code><a href="../reference/lasso.html">?lessSEM::lasso</a></code> for more
details on the lasso penalty. If you are interested in the general
purpose interface, have a look at <code>?lessEM::gpLasso</code>,
<code>?lesssEM::gpMcp</code>, etc. To get more details on implementing
the <strong>lessSEM</strong> optimizers in your own package, have a look
at the vignettes <code><a href="../articles/General-Purpose-Optimization.html">vignette('General-Purpose-Optimization')</a></code>
and <code><a href="../articles/The-optimizer-interface.html">vignette('The-optimizer-interface')</a></code> and at the <a href="https://github.com/jhorzek/lessLM" class="external-link"><strong>lessLM</strong></a>
package.</p>
</div>
<div class="section level2">
<h2 id="table-of-the-most-relevant-functions">Table of the most relevant functions<a class="anchor" aria-label="anchor" href="#table-of-the-most-relevant-functions"></a>
</h2>
<p>Fitting <em>regularized SEM</em>:</p>
<table class="table">
<colgroup>
<col width="50%">
<col width="50%">
</colgroup>
<thead><tr class="header">
<th>function name</th>
<th>what it does</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>ridge</td>
<td>ridge regularization of SEM</td>
</tr>
<tr class="even">
<td>cvRidge</td>
<td>cross-validated ridge regularization of SEM</td>
</tr>
<tr class="odd">
<td>lasso</td>
<td>lasso regularization of SEM</td>
</tr>
<tr class="even">
<td>cvLasso</td>
<td>cross-validated lasso regularization of SEM</td>
</tr>
<tr class="odd">
<td>adaptiveLasso</td>
<td>adaptive lasso regularization of SEM</td>
</tr>
<tr class="even">
<td>cvAdaptiveLasso</td>
<td>cross-validated adaptive lasso regularization of SEM</td>
</tr>
<tr class="odd">
<td>elasticNet</td>
<td>elastic net regularization of SEM</td>
</tr>
<tr class="even">
<td>cvElasticNet</td>
<td>cross-validated elastic net regularization of SEM</td>
</tr>
<tr class="odd">
<td>cappedL1</td>
<td>cappedL1 regularization of SEM</td>
</tr>
<tr class="even">
<td>cvCappedL1</td>
<td>cross-validated cappedL1 regularization of SEM</td>
</tr>
<tr class="odd">
<td>lsp</td>
<td>lsp regularization of SEM</td>
</tr>
<tr class="even">
<td>cvLsp</td>
<td>cross-validated lsp regularization of SEM</td>
</tr>
<tr class="odd">
<td>mcp</td>
<td>mcp regularization of SEM</td>
</tr>
<tr class="even">
<td>cvMcp</td>
<td>cross-validated mcp regularization of SEM</td>
</tr>
<tr class="odd">
<td>scad</td>
<td>scad regularization of SEM</td>
</tr>
<tr class="even">
<td>cvScad</td>
<td>cross-validated scad regularization of SEM</td>
</tr>
</tbody>
</table>
<p>Using the optimizers in <strong>lessSEM</strong> for <em>general
purpose optimization</em>:</p>
<table class="table">
<colgroup>
<col width="50%">
<col width="50%">
</colgroup>
<thead><tr class="header">
<th>function name</th>
<th>what it does</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>gpRidge</td>
<td>ridge regularization for general purpose optimization</td>
</tr>
<tr class="even">
<td>gpLasso</td>
<td>lasso regularization for general purpose optimization</td>
</tr>
<tr class="odd">
<td>gpAdaptiveLasso</td>
<td>adaptive lasso regularization for general purpose optimization</td>
</tr>
<tr class="even">
<td>gpElasticNet</td>
<td>elastic net regularization for general purpose optimization</td>
</tr>
<tr class="odd">
<td>gpCappedL1</td>
<td>cappedL1 regularization for general purpose optimization</td>
</tr>
<tr class="even">
<td>gpLsp</td>
<td>lsp regularization for general purpose optimization</td>
</tr>
<tr class="odd">
<td>gpMcp</td>
<td>mcp regularization for general purpose optimization</td>
</tr>
<tr class="even">
<td>gpScad</td>
<td>scad regularization for general purpose optimization</td>
</tr>
</tbody>
</table>
<p>Using the optimizers in <strong>lessSEM</strong> for <em>general
purpose optimization with C++ functions</em>:</p>
<table class="table">
<colgroup>
<col width="50%">
<col width="50%">
</colgroup>
<thead><tr class="header">
<th>function name</th>
<th>what it does</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>gpRidgeCpp</td>
<td>ridge regularization for general purpose optimization</td>
</tr>
<tr class="even">
<td>gpLassoCpp</td>
<td>lasso regularization for general purpose optimization</td>
</tr>
<tr class="odd">
<td>gpAdaptiveLassoCpp</td>
<td>adaptive lasso regularization for general purpose optimization</td>
</tr>
<tr class="even">
<td>gpElasticNetCpp</td>
<td>elastic net regularization for general purpose optimization</td>
</tr>
<tr class="odd">
<td>gpCappedL1Cpp</td>
<td>cappedL1 regularization for general purpose optimization</td>
</tr>
<tr class="even">
<td>gpLspCpp</td>
<td>lsp regularization for general purpose optimization</td>
</tr>
<tr class="odd">
<td>gpMcpCpp</td>
<td>mcp regularization for general purpose optimization</td>
</tr>
<tr class="even">
<td>gpScadCpp</td>
<td>scad regularization for general purpose optimization</td>
</tr>
</tbody>
</table>
</div>
<div class="section level2">
<h2 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h2>
<div class="section level3">
<h3 id="r---packages-software">R - Packages / Software<a class="anchor" aria-label="anchor" href="#r---packages-software"></a>
</h3>
<ul>
<li>
<a href="https://github.com/yrosseel/lavaan" class="external-link">lavaan</a> Rosseel, Y.
(2012). lavaan: An R Package for Structural Equation Modeling. Journal
of Statistical Software, 48(2), 1–36. <a href="https://doi.org/10.18637/jss.v048.i02" class="external-link uri">https://doi.org/10.18637/jss.v048.i02</a>
</li>
<li>
<a href="https://github.com/Rjacobucci/regsem" class="external-link">regsem</a>:
Jacobucci, R. (2017). regsem: Regularized Structural Equation Modeling.
ArXiv:1703.08489 [Stat]. <a href="http://arxiv.org/abs/1703.08489" class="external-link uri">http://arxiv.org/abs/1703.08489</a>
</li>
<li>
<a href="https://github.com/psyphh/lslx" class="external-link">lslx</a>: Huang, P.-H.
(2020). lslx: Semi-confirmatory structural equation modeling via
penalized likelihood. Journal of Statistical Software, 93(7). <a href="https://doi.org/10.18637/jss.v093.i07" class="external-link uri">https://doi.org/10.18637/jss.v093.i07</a>
</li>
<li>
<a href="https://cran.r-project.org/web/packages/fasta/index.html" class="external-link">fasta</a>:
Another implementation of the fista algorithm (Beck &amp; Teboulle,
2009)</li>
<li>
<a href="https://ensmallen.org/" class="external-link">ensmallen</a>: Curtin, R. R., Edel,
M., Prabhu, R. G., Basak, S., Lou, Z., &amp; Sanderson, C. (2021). The
ensmallen library for ﬂexible numerical optimization. Journal of Machine
Learning Research, 22, 1–6.</li>
<li>
<a href="https://rcppcore.github.io/RcppParallel/" class="external-link">RcppParallel</a>
Allaire J, Francois R, Ushey K, Vandenbrouck G, Geelnard M, Intel
(2023). <em>RcppParallel: Parallel Programming Tools for ‘Rcpp’</em>. R
package version 5.1.6, <a href="https://CRAN.R-project.org/package=RcppParallel" class="external-link uri">https://CRAN.R-project.org/package=RcppParallel</a>.</li>
</ul>
</div>
<div class="section level3">
<h3 id="regularized-structural-equation-modeling-1">Regularized Structural Equation Modeling<a class="anchor" aria-label="anchor" href="#regularized-structural-equation-modeling-1"></a>
</h3>
<ul>
<li>Huang, P.-H., Chen, H., &amp; Weng, L.-J. (2017). A Penalized
Likelihood Method for Structural Equation Modeling. Psychometrika,
82(2), 329–354. <a href="https://doi.org/10.1007/s11336-017-9566-9" class="external-link uri">https://doi.org/10.1007/s11336-017-9566-9</a>
</li>
<li>Huang, P.-H. (2018). A penalized likelihood method for multi-group
structural equation modelling. British Journal of Mathematical and
Statistical Psychology, 71(3), 499–522. <a href="https://doi.org/10.1111/bmsp.12130" class="external-link uri">https://doi.org/10.1111/bmsp.12130</a>
</li>
<li>Jacobucci, R., Grimm, K. J., &amp; McArdle, J. J. (2016).
Regularized Structural Equation Modeling. Structural Equation Modeling:
A Multidisciplinary Journal, 23(4), 555–566. <a href="https://doi.org/10.1080/10705511.2016.1154793" class="external-link uri">https://doi.org/10.1080/10705511.2016.1154793</a>
</li>
</ul>
</div>
<div class="section level3">
<h3 id="penalty-functions">Penalty Functions<a class="anchor" aria-label="anchor" href="#penalty-functions"></a>
</h3>
<ul>
<li>Candès, E. J., Wakin, M. B., &amp; Boyd, S. P. (2008). Enhancing
Sparsity by Reweighted l1 Minimization. Journal of Fourier Analysis and
Applications, 14(5–6), 877–905. <a href="https://doi.org/10.1007/s00041-008-9045-x" class="external-link uri">https://doi.org/10.1007/s00041-008-9045-x</a>
</li>
<li>Fan, J., &amp; Li, R. (2001). Variable selection via nonconcave
penalized likelihood and its oracle properties. Journal of the American
Statistical Association, 96(456), 1348–1360. <a href="https://doi.org/10.1198/016214501753382273" class="external-link uri">https://doi.org/10.1198/016214501753382273</a>
</li>
<li>Hoerl, A. E., &amp; Kennard, R. W. (1970). Ridge Regression: Biased
Estimation for Nonorthogonal Problems. Technometrics, 12(1), 55–67. <a href="https://doi.org/10.1080/00401706.1970.10488634" class="external-link uri">https://doi.org/10.1080/00401706.1970.10488634</a>
</li>
<li>Tibshirani, R. (1996). Regression shrinkage and selection via the
lasso. Journal of the Royal Statistical Society. Series B
(Methodological), 58(1), 267–288.</li>
<li>Zhang, C.-H. (2010). Nearly unbiased variable selection under
minimax concave penalty. The Annals of Statistics, 38(2), 894–942. <a href="https://doi.org/10.1214/09-AOS729" class="external-link uri">https://doi.org/10.1214/09-AOS729</a>
</li>
<li>Zhang, T. (2010). Analysis of Multi-stage Convex Relaxation for
Sparse Regularization. Journal of Machine Learning Research, 11,
1081–1107.</li>
<li>Zou, H. (2006). The adaptive lasso and its oracle properties.
Journal of the American Statistical Association, 101(476), 1418–1429. <a href="https://doi.org/10.1198/016214506000000735" class="external-link uri">https://doi.org/10.1198/016214506000000735</a>
</li>
<li>Zou, H., &amp; Hastie, T. (2005). Regularization and variable
selection via the elastic net. Journal of the Royal Statistical Society:
Series B, 67(2), 301–320. <a href="https://doi.org/10.1111/j.1467-9868.2005.00503.x" class="external-link uri">https://doi.org/10.1111/j.1467-9868.2005.00503.x</a>
</li>
</ul>
</div>
<div class="section level3">
<h3 id="optimizer">Optimizer<a class="anchor" aria-label="anchor" href="#optimizer"></a>
</h3>
<div class="section level4">
<h4 id="glmnet">GLMNET<a class="anchor" aria-label="anchor" href="#glmnet"></a>
</h4>
<ul>
<li>Friedman, J., Hastie, T., &amp; Tibshirani, R. (2010).
Regularization paths for generalized linear models via coordinate
descent. Journal of Statistical Software, 33(1), 1–20. <a href="https://doi.org/10.18637/jss.v033.i01" class="external-link uri">https://doi.org/10.18637/jss.v033.i01</a>
</li>
<li>Yuan, G.-X., Ho, C.-H., &amp; Lin, C.-J. (2012). An improved GLMNET
for l1-regularized logistic regression. The Journal of Machine Learning
Research, 13, 1999–2030. <a href="https://doi.org/10.1145/2020408.2020421" class="external-link uri">https://doi.org/10.1145/2020408.2020421</a>
</li>
</ul>
</div>
<div class="section level4">
<h4 id="variants-of-ista">Variants of ISTA<a class="anchor" aria-label="anchor" href="#variants-of-ista"></a>
</h4>
<ul>
<li>Beck, A., &amp; Teboulle, M. (2009). A Fast Iterative
Shrinkage-Thresholding Algorithm for Linear Inverse Problems. SIAM
Journal on Imaging Sciences, 2(1), 183–202. <a href="https://doi.org/10.1137/080716542" class="external-link uri">https://doi.org/10.1137/080716542</a>
</li>
<li>Gong, P., Zhang, C., Lu, Z., Huang, J., &amp; Ye, J. (2013). A
general iterative shrinkage and thresholding algorithm for non-convex
regularized optimization problems. Proceedings of the 30th International
Conference on Machine Learning, 28(2)(2), 37–45.</li>
<li>Parikh, N., &amp; Boyd, S. (2013). Proximal Algorithms. Foundations
and Trends in Optimization, 1(3), 123–231.</li>
</ul>
</div>
</div>
</div>
<div class="section level2">
<h2 id="important-notes">Important Notes<a class="anchor" aria-label="anchor" href="#important-notes"></a>
</h2>
<p>THE SOFTWARE IS PROVIDED ‘AS IS’, WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Jannik H. Orzek.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
