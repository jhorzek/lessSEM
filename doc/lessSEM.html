<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>lessSEM</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">lessSEM</h1>



<div id="regularized-structural-equation-modeling" class="section level2">
<h2>Regularized Structural Equation Modeling</h2>
<p>Regularized structural equation modeling (REGSEM) has been proposed
by Jacobucci et al. (2016) and Huang et al. (2017). The objective is to
reduce overfitting in small samples and to allow for more flexibility.
The general idea is to regularize some parameters towards zero. To this
end, a penalty function <span class="math inline">\(p(\pmb\theta)\)</span> is added to the vanilla
objective function. In lessSEM, this objective function is given by the
full information maximum likelihood function <span class="math inline">\(F_{\text{ML}}(\pmb\theta)\)</span>. The new
objective function is defined as:</p>
<p><span class="math display">\[F_{\text{REGSEM},\lambda}(\pmb\theta) =
F_{\text{ML}}(\pmb\theta)+ \lambda N p(\pmb\theta)\]</span></p>
<ul>
<li><span class="math inline">\(F_{\text{ML}}(\pmb\theta)\)</span> wants
all parameters to be close to the ordinary maximum likelihood
estimates</li>
<li><span class="math inline">\(p(\pmb\theta)\)</span> wants regularized
parameters to be close to zero</li>
<li><span class="math inline">\(\lambda\)</span> allows us to fine tune
which of the two forces mentioned above gets more influence on the final
parameter estimates</li>
<li><span class="math inline">\(N\)</span> is the sample size. Scaling
with <span class="math inline">\(N\)</span> is done to stay consistent
with results returned by <strong>regsem</strong> and
<strong>lslx</strong>.</li>
</ul>
<p>There are many different penalty functions which could be used. In
<strong>lessSEM</strong>, we have implemented the following
functions:</p>
<p><span class="math display">\[
\begin{array}{l|ll}
\text{penalty} &amp; \text{function} &amp; \text{reference}\\
\hline
\text{ridge} &amp; p( x_j) = \lambda x_j^2 &amp; \text{(Hoerl &amp;
Kennard, 1970)}\\
\text{lasso} &amp; p( x_j) = \lambda| x_j| &amp; \text{(Tibshirani,
1996)}\\
\text{adaptiveLasso} &amp; p( x_j) = \frac{1}{w_j}\lambda| x_j| &amp;
\text{(Zou, 2006)}\\
\text{elasticNet} &amp; p( x_j) = \alpha\lambda|x_j| + (1-\alpha)\lambda
x_j^2 &amp; \text{(Zou &amp; Hastie, 2005)}\\
\text{cappedL1} &amp; p( x_j) = \lambda \min(| x_j|, \theta); \theta
&gt; 0 &amp; \text{(Zhang, 2010)}\\
\text{lsp} &amp; p( x_j) = \lambda \log(1 + |x_j|\theta); \theta &gt; 0
&amp; \text{(Candès et al., 2008)} \\
\text{scad} &amp; p( x_j) = \begin{cases}
\lambda |x_j| &amp; \text{if } |x_j| \leq \lambda\\
\frac{-x_j^2 + 2\theta\lambda |x_j| - \lambda^2}{2(\theta -1)} &amp;
\text{if } \lambda &lt; |x_j| \leq \lambda\theta \\
(\theta + 1) \lambda^2/2 &amp; \text{if } |x_j| \geq \theta\lambda\\
\end{cases}; \theta &gt; 2 &amp; \text{(Fan &amp; Li, 2001)} \\
\text{mcp} &amp; p( x_j) =
\begin{cases}
\lambda |x_j| - x_j^2/(2\theta) &amp; \text{if } |x_j| \leq
\theta\lambda\\
\theta\lambda^2/2 &amp; \text{if } |x_j| &gt; \lambda\theta
\end{cases}; \theta &gt; 0 &amp; \text{(Zhang, 2010)}
\end{array}
\]</span></p>
</div>
<div id="objectives" class="section level2">
<h2>Objectives</h2>
<p>The objectives of <strong>lessSEM</strong> are two-fold</p>
<ol style="list-style-type: decimal">
<li>We wanted to test general purpose optimizers (the default in regsem
1.8.0 is solnp) against specialized optimizers (the default in lslx is a
variant of GLMNET)</li>
<li>To make the optimizers used within <strong>lessSEM</strong>
available for other researchers in order to simplify the implementation
of new regularized SEM</li>
</ol>
</div>
<div id="regularizing-sem" class="section level2">
<h2>Regularizing SEM</h2>
<p><strong>lessSEM</strong> is heavily inspired by the
<strong>regsem</strong> package. It also builds on
<strong>lavaan</strong> to set up the model.</p>
<div id="setting-up-a-model" class="section level3">
<h3>Setting up a model</h3>
<p>First, start with lavaan:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lavaan)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; This is lavaan 0.6-12</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; lavaan is FREE software! Please report any bugs.</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lessSEM)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">4321</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># let&#39;s simulate data for a simple </span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># cfa with 7 observed variables</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> lessSEM<span class="sc">::</span><span class="fu">simulateExampleData</span>(<span class="at">N =</span> <span class="dv">50</span>, </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>                                     <span class="at">loadings =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">1</span>,<span class="dv">4</span>),</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>                                                  <span class="fu">rep</span>(<span class="dv">0</span>,<span class="dv">3</span>))</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(data)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;              y1         y2         y3         y4          y5         y6</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1,] -0.1737175 -0.1970204  1.1888412  1.8520403  0.16257957  1.8825526</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [2,] -1.5179940  0.9029781 -0.1726986 -0.3596920 -0.02092956 -0.5798953</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [3,]  0.6136418  0.2578986 -0.1359237  0.7703602  0.23502463  0.2001872</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [4,] -0.5920933  0.2157830  1.6784758  1.8568433 -0.60458482  0.2219578</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [5,]  0.0763996 -1.1442382 -2.8122156  0.4899892  0.03453494  2.0457604</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [6,]  2.2504896  2.9742206  0.4353705  1.2338364  0.04693253 -0.6438847</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;              y7</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1,]  1.1383999</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [2,]  0.9020861</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [3,]  0.7986506</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [4,]  0.4736751</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [5,] -2.6721417</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [6,] -1.1386235</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="co"># we assume a single factor structure</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>lavaanSyntax <span class="ot">&lt;-</span> <span class="st">&quot;</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="st">      f =~ l1*y1 + l2*y2 + l3*y3 + l4*y4 + l5*y5 + l6*y6 + l7*y7 </span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="st">      f ~~ 1*f</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="st">      &quot;</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="co"># estimate the model with lavaan</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>lavaanModel <span class="ot">&lt;-</span> <span class="fu">cfa</span>(lavaanSyntax, </span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> data)</span></code></pre></div>
<p>Next, decide which parameters should be regularized. Let’s go with
l5-l7. In <strong>lessSEM</strong>, we always use the parameter labels
to specify which parameters should be regularized!</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>regularized <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;l5&quot;</span>, <span class="st">&quot;l6&quot;</span>, <span class="st">&quot;l7&quot;</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="co"># tip: we can use paste to make this easier:</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>regularized <span class="ot">&lt;-</span> <span class="fu">paste0</span>(<span class="st">&quot;l&quot;</span>, <span class="dv">5</span><span class="sc">:</span><span class="dv">7</span>)</span></code></pre></div>
<p>Finally, we set up the regularized model. To this end, we must first
decide which penalty function we want to use. If we want to shrink
parameters without setting them to zero, we can use ridge
regularization. Otherwise, we must use any of the other penalty
functions mentioned above. In <strong>lessSEM</strong>, there is a
dedicated function for each of these penalties. The names of these
functions are identical to the “penalty” column in the table above. For
instance, let’s have a look at the lasso penalty:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>fitLasso <span class="ot">&lt;-</span> <span class="fu">lasso</span>(<span class="at">lavaanModel =</span> lavaanModel, </span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">regularized =</span> regularized,</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">nLambdas =</span> <span class="dv">50</span>)</span></code></pre></div>
<p>Plot the paths to see what is going on:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fitLasso)</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p>Note that the parameters are pulled towards zero as <span class="math inline">\(\lambda\)</span> increases. Note also that we did
not specify specific values for <span class="math inline">\(\lambda\)</span> in the lasso function above.
Instead, we only specified how many <span class="math inline">\(\lambda\)</span>s we want to have
(<code>nLambdas=50</code>). If we use the lasso or adaptive lasso,
<strong>lessSEM</strong> can automatically compute which <span class="math inline">\(\lambda\)</span> is necessary to set all
parameters to zero. This is currently not supported for any of the other
penalties.</p>
<p>The plots returned by <strong>lessSEM</strong> are either
<strong>ggplot2</strong> elements (in case of a single tuning
parameter), or created with plotly (in case of 2 tuning parameters). You
can change a plot post-hoc:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fitLasso) <span class="sc">+</span> ggplot2<span class="sc">::</span><span class="fu">theme_bw</span>()</span></code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p>The <code>coef</code> function gives access to all parameter
estimates:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">coef</span>(fitLasso))</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       lambda alpha        l2        l3        l4            l5 l6 l7    y1~~y1</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 0.10348921     1 0.7520379 0.7532544 0.5741407  0.0000000000  0  0 0.8808496</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 0.10137719     1 0.7522379 0.7535474 0.5742076  0.0000000000  0  0 0.8811500</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 0.09926516     1 0.7522631 0.7535816 0.5742194  0.0000000000  0  0 0.8811890</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 0.09715314     1 0.7522599 0.7535805 0.5742164  0.0000000000  0  0 0.8811861</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 0.09504111     1 0.7522608 0.7535792 0.5742159  0.0000000000  0  0 0.8811829</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 0.09292909     1 0.7522082 0.7535469 0.5741706 -0.0006146394  0  0 0.8811050</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     y2~~y2   y3~~y3   y4~~y4    y5~~y5    y6~~y6  y7~~y7      y1~1      y2~1</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 1.148031 1.927737 1.080405 0.5710366 0.9628056 1.53201 0.1295361 0.1446137</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 1.147821 1.927434 1.080366 0.5710366 0.9628056 1.53201 0.1295361 0.1446137</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 1.147800 1.927406 1.080359 0.5710366 0.9628056 1.53201 0.1295361 0.1446137</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 1.147798 1.927400 1.080359 0.5710366 0.9628056 1.53201 0.1295361 0.1446137</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 1.147800 1.927403 1.080362 0.5710366 0.9628056 1.53201 0.1295361 0.1446137</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 1.147838 1.927434 1.080387 0.5710082 0.9628056 1.53201 0.1295361 0.1446137</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        y3~1      y4~1        y5~1       y6~1       y7~1</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 0.4210241 0.1480334 -0.05439108 0.05590112 0.02733187</span></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 0.4210241 0.1480334 -0.05439108 0.05590112 0.02733187</span></span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 0.4210241 0.1480334 -0.05439108 0.05590112 0.02733187</span></span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 0.4210241 0.1480334 -0.05439108 0.05590112 0.02733187</span></span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 0.4210241 0.1480334 -0.05439108 0.05590112 0.02733187</span></span>
<span id="cb6-22"><a href="#cb6-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 0.4210241 0.1480334 -0.05439108 0.05590112 0.02733187</span></span></code></pre></div>
<p>Now, let’s assume you also want to try out the scad penalty. In this
case, all you have to do is to replace the <code>lasso()</code> function
with the <code>scad()</code> function:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>fitScad <span class="ot">&lt;-</span> <span class="fu">scad</span>(<span class="at">lavaanModel =</span> lavaanModel, </span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>                <span class="at">regularized =</span> regularized,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">lambdas =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,.<span class="dv">1</span>),</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">thetas =</span> <span class="fu">seq</span>(<span class="fl">2.1</span>, <span class="dv">5</span>,<span class="at">length.out =</span> <span class="dv">4</span>))</span></code></pre></div>
<p>The scad penalty has two tuning parmeters <span class="math inline">\(\lambda\)</span> and <span class="math inline">\(\theta\)</span>. The naming follows that used by
Gong et al. (2013). We can plot the results again, however this requires
the <strong>plotly</strong> package and is currently not supported in
Rmarkdown.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fitScad)</span></code></pre></div>
<p>The parameter estimates can again be accessed with the
<code>coef()</code> function:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">coef</span>(fitScad))</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   lambda theta        l2        l3        l4          l5         l6          l7</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1    0.0   2.1 0.7239911 0.7319714 0.5688589 -0.05622015 0.01659171 -0.08937208</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2    0.1   2.1 0.7520576 0.7532832 0.5741473  0.00000000 0.00000000  0.00000000</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3    0.2   2.1 0.7522396 0.7535498 0.5742082  0.00000000 0.00000000  0.00000000</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4    0.3   2.1 0.7522622 0.7535810 0.5742190  0.00000000 0.00000000  0.00000000</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5    0.4   2.1 0.7522598 0.7535800 0.5742161  0.00000000 0.00000000  0.00000000</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6    0.5   2.1 0.7522600 0.7535788 0.5742161  0.00000000 0.00000000  0.00000000</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      y1~~y1   y2~~y2   y3~~y3   y4~~y4    y5~~y5    y6~~y6   y7~~y7      y1~1</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 0.8492389 1.177799 1.949500 1.082941 0.5684487 0.9625806 1.525471 0.1295361</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 0.8808792 1.148010 1.927707 1.080401 0.5710366 0.9628056 1.532010 0.1295361</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 0.8811526 1.147820 1.927432 1.080365 0.5710366 0.9628056 1.532010 0.1295361</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 0.8811879 1.147800 1.927406 1.080360 0.5710366 0.9628056 1.532010 0.1295361</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 0.8811854 1.147798 1.927400 1.080360 0.5710366 0.9628056 1.532010 0.1295361</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 0.8811825 1.147800 1.927403 1.080362 0.5710366 0.9628056 1.532010 0.1295361</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        y2~1      y3~1      y4~1        y5~1       y6~1       y7~1</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 0.1446137 0.4210241 0.1480334 -0.05439108 0.05590112 0.02733187</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 0.1446137 0.4210241 0.1480334 -0.05439108 0.05590112 0.02733187</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 0.1446137 0.4210241 0.1480334 -0.05439108 0.05590112 0.02733187</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 0.1446137 0.4210241 0.1480334 -0.05439108 0.05590112 0.02733187</span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 0.1446137 0.4210241 0.1480334 -0.05439108 0.05590112 0.02733187</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 0.1446137 0.4210241 0.1480334 -0.05439108 0.05590112 0.02733187</span></span></code></pre></div>
</div>
<div id="selecting-a-model" class="section level3">
<h3>Selecting a model</h3>
<p>To select a model and report the final parameter estimates, you can
use the AIC or BIC (other information criteria are also possible, but
currently not implemented). There are two ways to use these information
criteria.</p>
<p>First, you can compute them and select the model yourself:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>AICs <span class="ot">&lt;-</span> <span class="fu">AIC</span>(fitLasso)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(AICs)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       lambda alpha     m2LL  regM2LL nonZeroParameters convergence      AIC</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 0.10348921     1 1071.078 1071.078                17        TRUE 1105.078</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 0.10137719     1 1071.078 1071.078                17        TRUE 1105.078</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 0.09926516     1 1071.078 1071.078                17        TRUE 1105.078</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 0.09715314     1 1071.078 1071.078                17        TRUE 1105.078</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 0.09504111     1 1071.078 1071.078                17        TRUE 1105.078</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 6 0.09292909     1 1071.075 1071.078                18        TRUE 1107.075</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>fitLasso<span class="sc">@</span>parameters[<span class="fu">which.min</span>(AICs<span class="sc">$</span>AIC),]</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       lambda alpha        l2        l3        l4 l5 l6 l7    y1~~y1 y2~~y2</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 0.09504111     1 0.7522608 0.7535792 0.5742159  0  0  0 0.8811829 1.1478</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     y3~~y3   y4~~y4    y5~~y5    y6~~y6  y7~~y7      y1~1      y2~1      y3~1</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 1.927403 1.080362 0.5710366 0.9628056 1.53201 0.1295361 0.1446137 0.4210241</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        y4~1        y5~1       y6~1       y7~1</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 0.1480334 -0.05439108 0.05590112 0.02733187</span></span></code></pre></div>
<p>An easier way is to use the <code>coef()</code> function again:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(fitLasso, <span class="at">criterion =</span> <span class="st">&quot;AIC&quot;</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       lambda alpha        l2        l3        l4 l5 l6 l7    y1~~y1 y2~~y2</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 0.09504111     1 0.7522608 0.7535792 0.5742159  0  0  0 0.8811829 1.1478</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     y3~~y3   y4~~y4    y5~~y5    y6~~y6  y7~~y7      y1~1      y2~1      y3~1</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 1.927403 1.080362 0.5710366 0.9628056 1.53201 0.1295361 0.1446137 0.4210241</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        y4~1        y5~1       y6~1       y7~1</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 0.1480334 -0.05439108 0.05590112 0.02733187</span></span></code></pre></div>
<div id="cross-validation" class="section level4">
<h4>Cross-Validation</h4>
<p>A very good alternative to information criteria is the use of
cross-validation. In <strong>lessSEM</strong>, there is a dedicated
cross-validation function for each of the penalties discussed above.
Let’s look at the <code>lsp()</code> penalty this time. Now, for your
non-cross-validated lsp, you would use</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>fitLsp <span class="ot">&lt;-</span> <span class="fu">lsp</span>(<span class="at">lavaanModel =</span> lavaanModel, </span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>              <span class="at">regularized =</span> regularized,</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">lambdas =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,.<span class="dv">1</span>),</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">thetas =</span> <span class="fu">seq</span>(.<span class="dv">1</span>,<span class="dv">2</span>,<span class="at">length.out =</span> <span class="dv">4</span>))</span></code></pre></div>
<p>To use a cross-validated version of the lsp, simply use the
<code>cv</code> prefix. The function is called <code>cvLsp()</code>:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>fitCvLsp <span class="ot">&lt;-</span> <span class="fu">cvLsp</span>(<span class="at">lavaanModel =</span> lavaanModel, </span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">regularized =</span> regularized,</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">lambdas =</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,.<span class="dv">1</span>),</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">thetas =</span> <span class="fu">seq</span>(.<span class="dv">1</span>,<span class="dv">2</span>,<span class="at">length.out =</span> <span class="dv">4</span>))</span></code></pre></div>
<p>The best model can now be accessed with</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(fitCvLsp)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          l2          l3          l4          l5          l6          l7 </span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  0.75203790  0.75325437  0.57414066  0.00000000  0.00000000  0.00000000 </span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      y1~~y1      y2~~y2      y3~~y3      y4~~y4      y5~~y5      y6~~y6 </span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  0.88084961  1.14803077  1.92773697  1.08040457  0.57103655  0.96280562 </span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      y7~~y7        y1~1        y2~1        y3~1        y4~1        y5~1 </span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  1.53201041  0.12953609  0.14461369  0.42102411  0.14803336 -0.05439108 </span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        y6~1        y7~1 </span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  0.05590112  0.02733187</span></span></code></pre></div>
</div>
</div>
<div id="missing-data" class="section level3">
<h3>Missing Data</h3>
<p>Most psychological data sets will have missing data. In
<strong>lessSEM</strong>, we follow the example of
<strong>regsem</strong> and use the full information maximum likelihood
function to account for this missingness. Identical to
<strong>regsem</strong>, <strong>lessSEM</strong> expects that you
already use the full information maximum likelihood method in
<strong>lavaan</strong>.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># let&#39;s simulate data for a simple </span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># cfa with 7 observed variables</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># and 10 % missing data</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> lessSEM<span class="sc">::</span><span class="fu">simulateExampleData</span>(<span class="at">N =</span> <span class="dv">100</span>, </span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>                                     <span class="at">loadings =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">1</span>,<span class="dv">4</span>),</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>                                                  <span class="fu">rep</span>(<span class="dv">0</span>,<span class="dv">3</span>)),</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>                                     <span class="at">percentMissing =</span> <span class="dv">10</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(data)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;               y1         y2         y3          y4         y5        y6</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1,]  0.60367543 -0.3206755 -0.5712115  0.36626658  0.6138552 0.8207451</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [2,]  0.37497661  2.0100766 -1.5925242 -0.02983920  0.2409065 1.1250778</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [3,]          NA  0.8134143  1.7803075  3.27710938 -0.3651732        NA</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [4,] -0.04379503  0.1369219 -1.9424719  0.40304282 -0.6435542 1.5412868</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [5,] -0.32969221         NA -1.6536493 -2.20991516  1.2462449 0.6725163</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [6,]  0.61738032  0.9116425  0.9196841  0.03340633  0.5553805 0.1209500</span></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;              y7</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1,]  0.6346473</span></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [2,]  0.8865902</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [3,] -0.8283463</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [4,]  0.0635044</span></span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [5,]         NA</span></span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [6,]  2.0956358</span></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a><span class="co"># we assume a single factor structure</span></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>lavaanSyntax <span class="ot">&lt;-</span> <span class="st">&quot;</span></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a><span class="st">      f =~ l1*y1 + l2*y2 + l3*y3 + l4*y4 + l5*y5 + l6*y6 + l7*y7 </span></span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a><span class="st">      f ~~ 1*f</span></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a><span class="st">      &quot;</span></span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a><span class="co"># estimate the model with lavaan</span></span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>lavaanModel <span class="ot">&lt;-</span> <span class="fu">cfa</span>(lavaanSyntax, </span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>                   <span class="at">data =</span> data,</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>                   <span class="at">missing =</span> <span class="st">&quot;ml&quot;</span>) <span class="co"># important: use fiml for missing data</span></span></code></pre></div>
<p>Note that we added the argument <code>missing = &#39;ml&#39;</code> to the
<strong>lavaan</strong> model. This tells <strong>lavaan</strong> to use
the full information maximum likelihood function.</p>
<p>Next, pass this model to any of the penalty functions in
<strong>lessSEM</strong>. <strong>lessSEM</strong> will automatically
switch to the full information maximum likelihood function as well:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>fitLasso <span class="ot">&lt;-</span> <span class="fu">lasso</span>(<span class="at">lavaanModel =</span> lavaanModel, </span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">regularized =</span> regularized,</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">nLambdas =</span> <span class="dv">10</span>)</span></code></pre></div>
<p>To check if <strong>lessSEM</strong> did actually use the full
information maximum likelihood, we can compare the 2log-likelihood of
<strong>lavaan</strong> and <strong>lessSEM</strong> when no penalty is
used (<span class="math inline">\(\lambda = 0\)</span>):</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>fitLasso <span class="ot">&lt;-</span> <span class="fu">lasso</span>(<span class="at">lavaanModel =</span> lavaanModel, </span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">regularized =</span> regularized,</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">lambdas =</span> <span class="dv">0</span>)</span></code></pre></div>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>fitLasso<span class="sc">@</span>fits<span class="sc">$</span>m2LL</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 2034.104</span></span></code></pre></div>
<p>Compare this to:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="sc">-</span><span class="dv">2</span><span class="sc">*</span><span class="fu">logLik</span>(lavaanModel)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; &#39;log Lik.&#39; 2034.104 (df=20)</span></span></code></pre></div>
</div>
</div>
<div id="changing-the-optimizer" class="section level2">
<h2>Changing the optimizer</h2>
<p><strong>lessSEM</strong> comes with two specialized optimization
procedures for elastic-net-type penalties: ista and glmnet. Currently,
the default is ista, which does not require the computation of a Hessian
matrix. However, this comes at a price: ista optimization tends to call
the fit and gradient function a lot more than glment. If you are using
an elastic-net-type penalty (ridge, lasso, adaptive lasso, or elastic
net), we recommend that you first test the glmnet optimizer and then
switch to ista if glmnet results in errors due to the Hessian matrix.
Switching to glmnet is done as follows:</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>fitLasso <span class="ot">&lt;-</span> <span class="fu">lasso</span>(<span class="at">lavaanModel =</span> lavaanModel, </span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>                  <span class="at">regularized =</span> regularized,</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">nLambdas =</span> <span class="dv">10</span>,</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">method =</span> <span class="st">&quot;glmnet&quot;</span>, <span class="co"># change the method</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>                  <span class="at">control =</span> <span class="fu">controlGlmnet</span>() <span class="co"># change the control argument</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>                  )</span></code></pre></div>
</div>
<div id="parameter-transformations" class="section level2">
<h2>Parameter transformations</h2>
<p><strong>lessSEM</strong> allows for parameter transformations. This
is explained in detail in the vignette Parameter-transformations (see
<code>vignette(&quot;Parameter-transformations&quot;, package = &quot;lessSEM&quot;)</code>).
To provide a short example, let’s have a look at the political democracy
data set:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># example from ?lavaan::sem</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lavaan)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>modelSyntax <span class="ot">&lt;-</span> <span class="st">&#39; </span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="st">  # latent variable definitions</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="st">     ind60 =~ x1 + x2 + x3</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="st">     dem60 =~ y1 + a*y2 + b*y3 + c*y4</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="st">     dem65 =~ y5 + a*y6 + b*y7 + c*y8</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="st">  # regressions</span></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="st">    dem60 ~ ind60</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="st">    dem65 ~ ind60 + dem60</span></span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="st">  # residual correlations</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a><span class="st">    y1 ~~ y5</span></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a><span class="st">    y2 ~~ y4 </span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="st">    y3 ~~ y7</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a><span class="st">    y4 ~~ y8</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a><span class="st">    y6 ~~ y8</span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a><span class="st">&#39;</span></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>lavaanFit <span class="ot">&lt;-</span> <span class="fu">sem</span>(<span class="at">model =</span> modelSyntax,</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data =</span> PoliticalDemocracy)</span></code></pre></div>
<p>Note that in the model estimated above, loadings on the latent
variables are constrained to equality over time. We could also relax
this assumption by allowing for time point specific loadings:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(lavaan)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>modelSyntax <span class="ot">&lt;-</span> <span class="st">&#39; </span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="st">  # latent variable definitions</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="st">     ind60 =~ x1 + x2 + x3</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="st">     dem60 =~ y1 + a1*y2 + b1*y3 + c1*y4</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="st">     dem65 =~ y5 + a2*y6 + b2*y7 + c2*y8</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="st">  # regressions</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="st">    dem60 ~ ind60</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="st">    dem65 ~ ind60 + dem60</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="st">  # residual correlations</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="st">    y1 ~~ y5</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="st">    y2 ~~ y4 </span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="st">    y3 ~~ y7</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="st">    y4 ~~ y8</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="st">    y6 ~~ y8</span></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="st">&#39;</span></span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>lavaanFit <span class="ot">&lt;-</span> <span class="fu">sem</span>(<span class="at">model =</span> modelSyntax,</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>                 <span class="at">data =</span> PoliticalDemocracy)</span></code></pre></div>
<p>Deciding between both approaches can be difficult as there may be
some parameters for which equality over time holds, while others violate
the assumption. Here, transformations can be used to regularize
differences between parameters. To this end, we define the
transformations:</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>transformations <span class="ot">&lt;-</span> <span class="st">&quot;</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="st"># IMPORTANT: Our transformations always have to start with the follwing line:</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="st">parameters: a1, a2, b1, b2, c1, c2, delta_a2, delta_b2, delta_c2</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="st"># In the line above, we defined the names of the parameters which we</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="st"># want to use in our transformations. EACH AND EVERY PARAMETER USED IN</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="st"># THE FOLLOWING MUST BE STATED ABOVE. The line must always start with</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="st"># the keyword &#39;parameters&#39; followed by a colon. The parameters must be</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="st"># separated by commata.</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a><span class="st"># Now we can state our transformations:</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="st">a2 = a1 + delta_a2</span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="st">b2 = b1 + delta_b2</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="st">c2 = c1 + delta_c2</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a><span class="st">&quot;</span></span></code></pre></div>
<p>Next, we have to pass the <code>transformations</code> variable to
the penalty function:</p>
<pre><code>#&gt; Compiling the transformation function ... done.
#&gt; Automatically selecting the maximal lambda value.
#&gt; Note: This may fail if a model with all regularized parameters set to zero is not identified.
#&gt; 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |=                                                                     |   1%
  |                                                                            
  |=                                                                     |   2%
  |                                                                            
  |==                                                                    |   3%
  |                                                                            
  |===                                                                   |   4%
  |                                                                            
  |====                                                                  |   5%
  |                                                                            
  |====                                                                  |   6%
  |                                                                            
  |=====                                                                 |   7%
  |                                                                            
  |======                                                                |   8%
  |                                                                            
  |======                                                                |   9%
  |                                                                            
  |=======                                                               |  10%
  |                                                                            
  |========                                                              |  11%
  |                                                                            
  |========                                                              |  12%
  |                                                                            
  |=========                                                             |  13%
  |                                                                            
  |==========                                                            |  14%
  |                                                                            
  |==========                                                            |  15%
  |                                                                            
  |===========                                                           |  16%
  |                                                                            
  |============                                                          |  17%
  |                                                                            
  |=============                                                         |  18%
  |                                                                            
  |=============                                                         |  19%
  |                                                                            
  |==============                                                        |  20%
  |                                                                            
  |===============                                                       |  21%
  |                                                                            
  |===============                                                       |  22%
  |                                                                            
  |================                                                      |  23%
  |                                                                            
  |=================                                                     |  24%
  |                                                                            
  |==================                                                    |  25%
  |                                                                            
  |==================                                                    |  26%
  |                                                                            
  |===================                                                   |  27%
  |                                                                            
  |====================                                                  |  28%
  |                                                                            
  |====================                                                  |  29%
  |                                                                            
  |=====================                                                 |  30%
  |                                                                            
  |======================                                                |  31%
  |                                                                            
  |======================                                                |  32%
  |                                                                            
  |=======================                                               |  33%
  |                                                                            
  |========================                                              |  34%
  |                                                                            
  |========================                                              |  35%
  |                                                                            
  |=========================                                             |  36%
  |                                                                            
  |==========================                                            |  37%
  |                                                                            
  |===========================                                           |  38%
  |                                                                            
  |===========================                                           |  39%
  |                                                                            
  |============================                                          |  40%
  |                                                                            
  |=============================                                         |  41%
  |                                                                            
  |=============================                                         |  42%
  |                                                                            
  |==============================                                        |  43%
  |                                                                            
  |===============================                                       |  44%
  |                                                                            
  |================================                                      |  45%
  |                                                                            
  |================================                                      |  46%
  |                                                                            
  |=================================                                     |  47%
  |                                                                            
  |==================================                                    |  48%
  |                                                                            
  |==================================                                    |  49%
  |                                                                            
  |===================================                                   |  50%
  |                                                                            
  |====================================                                  |  51%
  |                                                                            
  |====================================                                  |  52%
  |                                                                            
  |=====================================                                 |  53%
  |                                                                            
  |======================================                                |  54%
  |                                                                            
  |======================================                                |  55%
  |                                                                            
  |=======================================                               |  56%
  |                                                                            
  |========================================                              |  57%
  |                                                                            
  |=========================================                             |  58%
  |                                                                            
  |=========================================                             |  59%
  |                                                                            
  |==========================================                            |  60%
  |                                                                            
  |===========================================                           |  61%
  |                                                                            
  |===========================================                           |  62%
  |                                                                            
  |============================================                          |  63%
  |                                                                            
  |=============================================                         |  64%
  |                                                                            
  |==============================================                        |  65%
  |                                                                            
  |==============================================                        |  66%
  |                                                                            
  |===============================================                       |  67%
  |                                                                            
  |================================================                      |  68%
  |                                                                            
  |================================================                      |  69%
  |                                                                            
  |=================================================                     |  70%
  |                                                                            
  |==================================================                    |  71%
  |                                                                            
  |==================================================                    |  72%
  |                                                                            
  |===================================================                   |  73%
  |                                                                            
  |====================================================                  |  74%
  |                                                                            
  |====================================================                  |  75%
  |                                                                            
  |=====================================================                 |  76%
  |                                                                            
  |======================================================                |  77%
  |                                                                            
  |=======================================================               |  78%
  |                                                                            
  |=======================================================               |  79%
  |                                                                            
  |========================================================              |  80%
  |                                                                            
  |=========================================================             |  81%
  |                                                                            
  |=========================================================             |  82%
  |                                                                            
  |==========================================================            |  83%
  |                                                                            
  |===========================================================           |  84%
  |                                                                            
  |============================================================          |  85%
  |                                                                            
  |============================================================          |  86%
  |                                                                            
  |=============================================================         |  87%
  |                                                                            
  |==============================================================        |  88%
  |                                                                            
  |==============================================================        |  89%
  |                                                                            
  |===============================================================       |  90%
  |                                                                            
  |================================================================      |  91%
  |                                                                            
  |================================================================      |  92%
  |                                                                            
  |=================================================================     |  93%
  |                                                                            
  |==================================================================    |  94%
  |                                                                            
  |==================================================================    |  95%
  |                                                                            
  |===================================================================   |  96%
  |                                                                            
  |====================================================================  |  97%
  |                                                                            
  |===================================================================== |  98%
  |                                                                            
  |===================================================================== |  99%
  |                                                                            
  |======================================================================| 100%</code></pre>
<p>To check if measurement invariance can be assumed, we can select the
best model using information criteria:</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(lassoFit, <span class="at">criterion =</span> <span class="st">&quot;BIC&quot;</span>)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       lambda alpha ind60=~x2 ind60=~x3       a1       b1       c1 dem60~ind60</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 10 0.2195295     1  2.182549   1.81893 1.211031 1.167946 1.234059    1.453432</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    dem65~ind60 dem65~dem60   y1~~y5   y2~~y4  y3~~y7    y4~~y8   y6~~y8</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 10   0.5935805   0.8658072 0.555727 1.593035 0.78177 0.6534623 1.533625</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        x1~~x1    x2~~x2    x3~~x3   y1~~y1   y2~~y2   y3~~y3   y4~~y4   y5~~y5</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 10 0.08199255 0.1176495 0.4674845 1.792933 7.382751 5.017745 3.406141 2.285925</span></span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      y6~~y6   y7~~y7   y8~~y8 ind60~~ind60 dem60~~dem60 dem65~~dem65     x1~1</span></span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 10 4.896553 3.550616 3.449804    0.4479943     3.940867    0.2043752 5.054379</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        x2~1    x3~1     y1~1     y2~1    y3~1     y4~1     y5~1     y6~1</span></span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 10 4.792197 3.55769 5.464667 4.256443 6.56311 4.452533 5.136252 2.978074</span></span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        y7~1    y8~1 delta_a2 delta_b2 delta_c2</span></span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 10 6.196264 4.04339        0        0        0</span></span></code></pre></div>
<p>More details are provided in
<code>vignette(&quot;Parameter-transformations&quot;, package = &quot;lessSEM&quot;)</code>.</p>
</div>
<div id="more-information" class="section level2">
<h2>More information</h2>
<p>We provide more information in the documentation of the individual
functions. For instance, see <code>?lessSEM::lasso</code> for more
details on the lasso penalty. If you are interested in the general
purpose interface, have a look at <code>?lessEM::gpLasso</code>,
<code>?lesssEM::gpMcp</code>, etc. To get more details on implementing
the <strong>lessSEM</strong> optimizers in your own package, have a look
at the vignettes <code>vignette(&#39;General-Purpose-Optimization&#39;)</code>
and <code>vignette(&#39;The-optimizer-interface&#39;)</code> and at the <a href="https://github.com/jhorzek/lessLM">lessLM</a> package.</p>
</div>
<div id="table-of-the-most-relevant-functions" class="section level2">
<h2>Table of the most relevant functions</h2>
<p>Fitting <em>regularized SEM</em>:</p>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>function name</th>
<th>what it does</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ridge</td>
<td>ridge regularization of SEM</td>
</tr>
<tr class="even">
<td>cvRidge</td>
<td>cross-validated ridge regularization of SEM</td>
</tr>
<tr class="odd">
<td>lasso</td>
<td>lasso regularization of SEM</td>
</tr>
<tr class="even">
<td>cvLasso</td>
<td>cross-validated lasso regularization of SEM</td>
</tr>
<tr class="odd">
<td>adaptiveLasso</td>
<td>adaptive lasso regularization of SEM</td>
</tr>
<tr class="even">
<td>cvAdaptiveLasso</td>
<td>cross-validated adaptive lasso regularization of SEM</td>
</tr>
<tr class="odd">
<td>elasticNet</td>
<td>elastic net regularization of SEM</td>
</tr>
<tr class="even">
<td>cvElasticNet</td>
<td>cross-validated elastic net regularization of SEM</td>
</tr>
<tr class="odd">
<td>cappedL1</td>
<td>cappedL1 regularization of SEM</td>
</tr>
<tr class="even">
<td>cvCappedL1</td>
<td>cross-validated cappedL1 regularization of SEM</td>
</tr>
<tr class="odd">
<td>lsp</td>
<td>lsp regularization of SEM</td>
</tr>
<tr class="even">
<td>cvLsp</td>
<td>cross-validated lsp regularization of SEM</td>
</tr>
<tr class="odd">
<td>mcp</td>
<td>mcp regularization of SEM</td>
</tr>
<tr class="even">
<td>cvMcp</td>
<td>cross-validated mcp regularization of SEM</td>
</tr>
<tr class="odd">
<td>scad</td>
<td>scad regularization of SEM</td>
</tr>
<tr class="even">
<td>cvScad</td>
<td>cross-validated scad regularization of SEM</td>
</tr>
</tbody>
</table>
<p>Using the optimizers in <strong>lessSEM</strong> for <em>general
purpose optimization</em>:</p>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>function name</th>
<th>what it does</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>gpRidge</td>
<td>ridge regularization for general purpose optimization</td>
</tr>
<tr class="even">
<td>gpLasso</td>
<td>lasso regularization for general purpose optimization</td>
</tr>
<tr class="odd">
<td>gpAdaptiveLasso</td>
<td>adaptive lasso regularization for general purpose optimization</td>
</tr>
<tr class="even">
<td>gpElasticNet</td>
<td>elastic net regularization for general purpose optimization</td>
</tr>
<tr class="odd">
<td>gpCappedL1</td>
<td>cappedL1 regularization for general purpose optimization</td>
</tr>
<tr class="even">
<td>gpLsp</td>
<td>lsp regularization for general purpose optimization</td>
</tr>
<tr class="odd">
<td>gpMcp</td>
<td>mcp regularization for general purpose optimization</td>
</tr>
<tr class="even">
<td>gpScad</td>
<td>scad regularization for general purpose optimization</td>
</tr>
</tbody>
</table>
<p>Using the optimizers in <strong>lessSEM</strong> for <em>general
purpose optimization with C++ functions</em>:</p>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>function name</th>
<th>what it does</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>gpRidgeCpp</td>
<td>ridge regularization for general purpose optimization</td>
</tr>
<tr class="even">
<td>gpLassoCpp</td>
<td>lasso regularization for general purpose optimization</td>
</tr>
<tr class="odd">
<td>gpAdaptiveLassoCpp</td>
<td>adaptive lasso regularization for general purpose optimization</td>
</tr>
<tr class="even">
<td>gpElasticNetCpp</td>
<td>elastic net regularization for general purpose optimization</td>
</tr>
<tr class="odd">
<td>gpCappedL1Cpp</td>
<td>cappedL1 regularization for general purpose optimization</td>
</tr>
<tr class="even">
<td>gpLspCpp</td>
<td>lsp regularization for general purpose optimization</td>
</tr>
<tr class="odd">
<td>gpMcpCpp</td>
<td>mcp regularization for general purpose optimization</td>
</tr>
<tr class="even">
<td>gpScadCpp</td>
<td>scad regularization for general purpose optimization</td>
</tr>
</tbody>
</table>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<div id="r---packages-software" class="section level2">
<h2>R - Packages / Software</h2>
<ul>
<li><a href="https://github.com/yrosseel/lavaan">lavaan</a> Rosseel, Y.
(2012). lavaan: An R Package for Structural Equation Modeling. Journal
of Statistical Software, 48(2), 1–36. <a href="https://doi.org/10.18637/jss.v048.i02" class="uri">https://doi.org/10.18637/jss.v048.i02</a></li>
<li><a href="https://github.com/Rjacobucci/regsem">regsem</a>:
Jacobucci, R. (2017). regsem: Regularized Structural Equation Modeling.
ArXiv:1703.08489 [Stat]. <a href="http://arxiv.org/abs/1703.08489" class="uri">http://arxiv.org/abs/1703.08489</a></li>
<li><a href="https://github.com/psyphh/lslx">lslx</a>: Huang, P.-H.
(2020). lslx: Semi-confirmatory structural equation modeling via
penalized likelihood. Journal of Statistical Software, 93(7). <a href="https://doi.org/10.18637/jss.v093.i07" class="uri">https://doi.org/10.18637/jss.v093.i07</a></li>
<li><a href="https://cran.r-project.org/web/packages/fasta/index.html">fasta</a>:
Another implementation of the fista algorithm (Beck &amp; Teboulle,
2009)</li>
<li><a href="https://ensmallen.org/">ensmallen</a>: Curtin, R. R., Edel,
M., Prabhu, R. G., Basak, S., Lou, Z., &amp; Sanderson, C. (2021). The
ensmallen library for ﬂexible numerical optimization. Journal of Machine
Learning Research, 22, 1–6.</li>
</ul>
</div>
<div id="regularized-structural-equation-modeling-1" class="section level2">
<h2>Regularized Structural Equation Modeling</h2>
<ul>
<li>Huang, P.-H., Chen, H., &amp; Weng, L.-J. (2017). A Penalized
Likelihood Method for Structural Equation Modeling. Psychometrika,
82(2), 329–354. <a href="https://doi.org/10.1007/s11336-017-9566-9" class="uri">https://doi.org/10.1007/s11336-017-9566-9</a></li>
<li>Jacobucci, R., Grimm, K. J., &amp; McArdle, J. J. (2016).
Regularized Structural Equation Modeling. Structural Equation Modeling:
A Multidisciplinary Journal, 23(4), 555–566. <a href="https://doi.org/10.1080/10705511.2016.1154793" class="uri">https://doi.org/10.1080/10705511.2016.1154793</a></li>
</ul>
</div>
<div id="penalty-functions" class="section level2">
<h2>Penalty Functions</h2>
<ul>
<li>Candès, E. J., Wakin, M. B., &amp; Boyd, S. P. (2008). Enhancing
Sparsity by Reweighted l1 Minimization. Journal of Fourier Analysis and
Applications, 14(5–6), 877–905. <a href="https://doi.org/10.1007/s00041-008-9045-x" class="uri">https://doi.org/10.1007/s00041-008-9045-x</a></li>
<li>Fan, J., &amp; Li, R. (2001). Variable selection via nonconcave
penalized likelihood and its oracle properties. Journal of the American
Statistical Association, 96(456), 1348–1360. <a href="https://doi.org/10.1198/016214501753382273" class="uri">https://doi.org/10.1198/016214501753382273</a></li>
<li>Hoerl, A. E., &amp; Kennard, R. W. (1970). Ridge Regression: Biased
Estimation for Nonorthogonal Problems. Technometrics, 12(1), 55–67. <a href="https://doi.org/10.1080/00401706.1970.10488634" class="uri">https://doi.org/10.1080/00401706.1970.10488634</a></li>
<li>Tibshirani, R. (1996). Regression shrinkage and selection via the
lasso. Journal of the Royal Statistical Society. Series B
(Methodological), 58(1), 267–288.</li>
<li>Zhang, C.-H. (2010). Nearly unbiased variable selection under
minimax concave penalty. The Annals of Statistics, 38(2), 894–942. <a href="https://doi.org/10.1214/09-AOS729" class="uri">https://doi.org/10.1214/09-AOS729</a></li>
<li>Zhang, T. (2010). Analysis of Multi-stage Convex Relaxation for
Sparse Regularization. Journal of Machine Learning Research, 11,
1081–1107.</li>
<li>Zou, H. (2006). The adaptive lasso and its oracle properties.
Journal of the American Statistical Association, 101(476), 1418–1429. <a href="https://doi.org/10.1198/016214506000000735" class="uri">https://doi.org/10.1198/016214506000000735</a></li>
<li>Zou, H., &amp; Hastie, T. (2005). Regularization and variable
selection via the elastic net. Journal of the Royal Statistical Society:
Series B, 67(2), 301–320. <a href="https://doi.org/10.1111/j.1467-9868.2005.00503.x" class="uri">https://doi.org/10.1111/j.1467-9868.2005.00503.x</a></li>
</ul>
</div>
<div id="optimizer" class="section level2">
<h2>Optimizer</h2>
<div id="glmnet" class="section level3">
<h3>GLMNET</h3>
<ul>
<li>Friedman, J., Hastie, T., &amp; Tibshirani, R. (2010).
Regularization paths for generalized linear models via coordinate
descent. Journal of Statistical Software, 33(1), 1–20. <a href="https://doi.org/10.18637/jss.v033.i01" class="uri">https://doi.org/10.18637/jss.v033.i01</a></li>
<li>Yuan, G.-X., Ho, C.-H., &amp; Lin, C.-J. (2012). An improved GLMNET
for l1-regularized logistic regression. The Journal of Machine Learning
Research, 13, 1999–2030. <a href="https://doi.org/10.1145/2020408.2020421" class="uri">https://doi.org/10.1145/2020408.2020421</a></li>
</ul>
</div>
<div id="variants-of-ista" class="section level3">
<h3>Variants of ISTA</h3>
<ul>
<li>Beck, A., &amp; Teboulle, M. (2009). A Fast Iterative
Shrinkage-Thresholding Algorithm for Linear Inverse Problems. SIAM
Journal on Imaging Sciences, 2(1), 183–202. <a href="https://doi.org/10.1137/080716542" class="uri">https://doi.org/10.1137/080716542</a></li>
<li>Gong, P., Zhang, C., Lu, Z., Huang, J., &amp; Ye, J. (2013). A
general iterative shrinkage and thresholding algorithm for non-convex
regularized optimization problems. Proceedings of the 30th International
Conference on Machine Learning, 28(2)(2), 37–45.</li>
<li>Parikh, N., &amp; Boyd, S. (2013). Proximal Algorithms. Foundations
and Trends in Optimization, 1(3), 123–231.</li>
</ul>
</div>
</div>
</div>
<div id="important-notes" class="section level1">
<h1>Important Notes</h1>
<p>THE SOFTWARE IS PROVIDED ‘AS IS’, WITHOUT WARRANTY OF ANY KIND,
EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY
CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
